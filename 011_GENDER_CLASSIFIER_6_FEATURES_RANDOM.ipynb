{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GroupKFold, GridSearchCV  , StratifiedGroupKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "from random import sample, shuffle\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.base import clone\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_path_root = \"/home/bruno/Academico/Doctorado/Neuro_Fairness/Shu_Dataset/004_Dataset_6_Random_Feature_Extraction/\"\n",
    "dataset_path_root = \"/home/bzorzet/Academico/Neuro_Fairness/Shu_Dataset/002_Dataset_Traditional_Feature_Extraction/\"\n",
    "\n",
    "participants=[\"sub-001\",\"sub-002\",\"sub-003\",\"sub-004\",\"sub-005\",\n",
    "              \"sub-006\",\"sub-007\",\"sub-008\",\"sub-009\",\"sub-010\",\n",
    "              \"sub-011\",\"sub-012\",\"sub-013\",\"sub-014\",\"sub-015\",\n",
    "              \"sub-016\",\"sub-017\",\"sub-018\",\"sub-019\",\"sub-020\",\n",
    "              \"sub-021\",\"sub-022\",\"sub-023\",\"sub-024\",\"sub-025\"]\n",
    "sessions = [\"ses-01\",\"ses-02\",\"ses-03\",\"ses-04\",\"ses-05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset={}\n",
    "for participant in participants:\n",
    "    dataset[participant]={}\n",
    "    data_path=participant+\"_task_motorimagery_eeg_preprocessing_trad_feature.mat\"\n",
    "    data=sio.loadmat(dataset_path_root + data_path)\n",
    "    for session in sessions:\n",
    "        dataset[participant][session +'_data_band_power']=data[session +'_data_band_power']\n",
    "        dataset[participant][session +'_labels_trials']=data[session +'_labels_trials']\n",
    "    dataset[participant]['sfreq']=np.squeeze(data['sfreq'])\n",
    "    dataset[participant]['age']=np.squeeze(data['age'])\n",
    "    dataset[participant]['gender']=data['gender'][0]\n",
    "    dataset[participant]['group_medidator']=data['group_medidator'][0]\n",
    "    dataset[participant]['id_participant']=data['id_participant'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participantes hombres: ['sub-001', 'sub-002', 'sub-008', 'sub-012', 'sub-013', 'sub-015', 'sub-017', 'sub-018', 'sub-019', 'sub-021', 'sub-022', 'sub-023', 'sub-025']\n",
      "Participantes mujeres: ['sub-003', 'sub-004', 'sub-005', 'sub-006', 'sub-007', 'sub-009', 'sub-010', 'sub-011', 'sub-014', 'sub-016', 'sub-020', 'sub-024']\n"
     ]
    }
   ],
   "source": [
    "index_female = []\n",
    "index_male = []\n",
    "for participant in participants:\n",
    "    if dataset[participant]['gender'] == 'M':\n",
    "        index_male.append(participant)\n",
    "    elif dataset[participant]['gender'] == 'F':\n",
    "        index_female.append(participant)\n",
    "print(f\"Participantes hombres: {index_male}\")\n",
    "print(f\"Participantes mujeres: {index_female}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in participants:\n",
    "    data_ = np.concatenate((dataset[participant]['ses-01_data_band_power'],\n",
    "                            dataset[participant]['ses-02_data_band_power'],\n",
    "                            dataset[participant]['ses-03_data_band_power'],\n",
    "                            dataset[participant]['ses-04_data_band_power'],\n",
    "                            dataset[participant]['ses-05_data_band_power']),axis=0)\n",
    "    \n",
    "    dataset[participant]['data_band_power'] = data_\n",
    "    dataset[participant]['data_gender'] =  np.array(list(dataset[participant]['gender']) * data_.shape[0])\n",
    "    dataset[participant]['group_participant'] =  np.array(list([participant]) * data_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 6 #RANDOM SAMPLE QUANTITY\n",
    "N_sr = 100 #RANDOM SAMPLING QUANTITY\n",
    "\n",
    "N_folds = 20\n",
    "n_test_participant = 2\n",
    "n_val_participant = 2 \n",
    "n_ign_participant = 1\n",
    "max_iter = 200\n",
    "patience = 50 \n",
    "\n",
    "info_exp = {}\n",
    "for it_sr in range(N_sr):\n",
    "    info_folds = {}\n",
    "    info_clfs = {}\n",
    "\n",
    "    #Random sample per subject\n",
    "    for participant in participants:\n",
    "        X = dataset[participant]['data_band_power']\n",
    "        n_0 = X.shape[0]\n",
    "        n_1 = X.shape[1]\n",
    "        n_2 = X.shape[2]\n",
    "        X =X.reshape((n_0,n_1*n_2))\n",
    "        X_random = np.zeros((n_0,n_features))\n",
    "        for it0 in range(n_0):\n",
    "            X_random[it0,:]=sample(X[it0,:].tolist(), n_features)\n",
    "        dataset[participant]['data_random'] = np.array(X_random)\n",
    "\n",
    "    #Train Model    \n",
    "    for it in range(N_folds):\n",
    "        dic_aux = {}\n",
    "        \n",
    "        X_train = None\n",
    "        X_val = None\n",
    "        X_test = None \n",
    "        \n",
    "        X_train_ = None\n",
    "        X_val_ = None\n",
    "        X_test_ = None\n",
    "        \n",
    "        idx_male = index_male.copy()\n",
    "        idx_female = index_female.copy()\n",
    "        \n",
    "        # TEST PARTICIPANTS:\n",
    "        idx_male_test = sample(idx_male, n_test_participant)\n",
    "        idx_female_test = sample(idx_female, n_test_participant)\n",
    "        for it_ in range(n_test_participant):\n",
    "            idx_male.remove(idx_male_test[it_])\n",
    "            idx_female.remove(idx_female_test[it_])\n",
    "        idx_test = idx_male_test + idx_female_test\n",
    "        dic_aux['reg_idx_test'] = idx_test   \n",
    "        \n",
    "        # VALIDATION PARTICIPANTS:\n",
    "        idx_male_val = sample(idx_male, n_val_participant)\n",
    "        idx_female_val = sample(idx_female, n_val_participant)\n",
    "        for it_ in range(n_val_participant):\n",
    "            idx_male.remove(idx_male_val[it_])\n",
    "            idx_female.remove(idx_female_val[it_])\n",
    "        idx_val = idx_male_val + idx_female_val\n",
    "        dic_aux['reg_idx_val'] = idx_val  \n",
    "        \n",
    "        # TRAIN PARTICIPANTS:\n",
    "        idx_male_ignore = sample(idx_male, n_ign_participant)\n",
    "        for it_ in range(n_ign_participant):\n",
    "            idx_male.remove(idx_male_ignore[it_])\n",
    "        idx_male_train = idx_male.copy()\n",
    "        idx_female_train = idx_female.copy()\n",
    "        idx_train = idx_male_train + idx_female_train\n",
    "        dic_aux['reg_idx_train'] = idx_train    \n",
    "            \n",
    "        \n",
    "        # CONCATENAMOS EL CONJUNTO DE DATOS\n",
    "        # TEST\n",
    "        X_test = np.zeros((1,n_features))\n",
    "        Y_test = np.zeros(1)\n",
    "        for participant in idx_test:\n",
    "            X_test = np.concatenate((X_test, dataset[participant]['data_random']),axis=0)\n",
    "            Y_test = np.concatenate((Y_test, dataset[participant]['data_gender']),axis=0)\n",
    "        X_test = X_test[1:,:]\n",
    "        Y_test = Y_test[1:]\n",
    "        dic_aux['n_trials_test'] = {'male':np.sum(Y_test == 'M'),'female':np.sum(Y_test == 'F')}\n",
    "        dic_aux['proportion_trials_test'] = {'male':np.sum(Y_test == 'M')/(np.sum(Y_test == 'M')+np.sum(Y_test == 'F')),\n",
    "                                        'female':np.sum(Y_test == 'F')/(np.sum(Y_test == 'M')+np.sum(Y_test == 'F'))}\n",
    "        # VALIDATION\n",
    "        X_val = np.zeros((1,n_features))\n",
    "        Y_val = np.zeros(1)\n",
    "        for participant in idx_val:\n",
    "            X_val = np.concatenate((X_val, dataset[participant]['data_random']),axis=0)\n",
    "            Y_val = np.concatenate((Y_val, dataset[participant]['data_gender']),axis=0)\n",
    "        X_val = X_val[1:,:]\n",
    "        Y_val = Y_val[1:]\n",
    "        dic_aux['n_trials_val'] = {'male':np.sum(Y_val == 'M'),'female':np.sum(Y_val == 'F')}\n",
    "        dic_aux['proportion_trials_val'] = {'male':np.sum(Y_val == 'M')/(np.sum(Y_val == 'M')+np.sum(Y_val == 'F')),\n",
    "                                        'female':np.sum(Y_val == 'F')/(np.sum(Y_val == 'M')+np.sum(Y_val == 'F'))}\n",
    "            \n",
    "        # TRAIN\n",
    "        X_train = np.zeros((1,n_features))\n",
    "        Y_train = np.zeros(1)\n",
    "        for participant in idx_train:\n",
    "            X_train = np.concatenate((X_train, dataset[participant]['data_random']),axis=0)\n",
    "            Y_train = np.concatenate((Y_train, dataset[participant]['data_gender']),axis=0)\n",
    "        X_train = X_train[1:,:]\n",
    "        Y_train = Y_train[1:]\n",
    "        dic_aux['n_trials_train'] = {'male':np.sum(Y_train == 'M'),'female':np.sum(Y_train == 'F')}\n",
    "        dic_aux['proportion_trials_train'] = {'male':np.sum(Y_train == 'M')/(np.sum(Y_train == 'M')+np.sum(Y_train == 'F')),\n",
    "                                        'female':np.sum(Y_train == 'F')/(np.sum(Y_train == 'M')+np.sum(Y_train == 'F'))}   \n",
    "        \n",
    "        info_folds[f'fold_{it}']=dic_aux\n",
    "\n",
    "        \n",
    "        dic_aux={}\n",
    "         #-----------------------CLASSIFIER 1 -----------------------------#\n",
    "        acc_train = None\n",
    "        acc_val = None\n",
    "        acc_test = None\n",
    "        \n",
    "        tol = 1e-4\n",
    "        scaler = StandardScaler()\n",
    "        clf = LinearDiscriminantAnalysis(tol=tol)\n",
    "        \n",
    "        X_train_ = scaler.fit_transform(X_train, Y_train)\n",
    "        X_val_ = scaler.transform(X_val)\n",
    "        X_test_ = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        clf.fit(X_train_, Y_train)\n",
    "        acc_train = clf.score(X_train_ , Y_train)\n",
    "        acc_val = clf.score(X_val_ , Y_val)\n",
    "        acc_test = clf.score(X_test_, Y_test)\n",
    "        \n",
    "        dic_aux['clf_1']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test}\n",
    "\n",
    "\n",
    "\n",
    "        #-----------------------CLASSIFIER 2 -----------------------------#\n",
    "        acc_train = None\n",
    "        acc_val = None\n",
    "        acc_test = None\n",
    "        \n",
    "        tol = 1e-4\n",
    "        scaler = StandardScaler()\n",
    "        clf = svm.SVC(C=1.0, kernel='linear', tol=tol)\n",
    "        \n",
    "        X_train_ = scaler.fit_transform(X_train, Y_train)\n",
    "        X_val_ = scaler.transform(X_val)\n",
    "        X_test_ = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        clf.fit(X_train_, Y_train)\n",
    "        acc_train = clf.score(X_train_ , Y_train)\n",
    "        acc_val = clf.score(X_val_ , Y_val)\n",
    "        acc_test = clf.score(X_test_, Y_test)\n",
    "        \n",
    "        dic_aux['clf_2']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test}\n",
    "        \n",
    "        # #-----------------------CLASSIFIER 3 -----------------------------#\n",
    "        # acc_train = None\n",
    "        # acc_val = None\n",
    "        # acc_test = None\n",
    "        \n",
    "        # tol = 1e-4\n",
    "        # scaler = StandardScaler()\n",
    "        # clf = svm.SVC(C=1.0, kernel='rbf', tol=tol)\n",
    "        \n",
    "        # X_train_ = scaler.fit_transform(X_train, Y_train)\n",
    "        # X_val_ = scaler.transform(X_val)\n",
    "        # X_test_ = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        # clf.fit(X_train_, Y_train)\n",
    "        # acc_train = clf.score(X_train_ , Y_train)\n",
    "        # acc_val = clf.score(X_val_ , Y_val)\n",
    "        # acc_test = clf.score(X_test_, Y_test)\n",
    "        \n",
    "        # dic_aux['clf_3']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test}\n",
    "        \n",
    "        \n",
    "        # #-----------------------CLASSIFIER 4 -----------------------------#\n",
    "        # acc_train_scores = []\n",
    "        # acc_val_scores = []\n",
    "        # acc_train = 0\n",
    "        # acc_val = 0\n",
    "        # acc_test = 0\n",
    "        \n",
    "        # # Counter for patience\n",
    "        # it_patience = 0\n",
    "        \n",
    "        # # Best classifier in early stopping\n",
    "        # best_clf = None\n",
    "        # it_stop = 0 \n",
    "        \n",
    "        # scaler = StandardScaler()\n",
    "        # clf = MLPClassifier(hidden_layer_sizes=(10,8,5), activation='relu', solver='adam', alpha=0.0001,\n",
    "        #                     learning_rate='constant', learning_rate_init=0.01,max_iter=max_iter)\n",
    "        # classes = np.unique(Y_train)\n",
    "\n",
    "        # for it_ in range(max_iter):\n",
    "        #     # Scaler fit/transform\n",
    "        #     scaler.partial_fit(X_train, Y_train)\n",
    "        #     X_train_ = scaler.transform(X_train)\n",
    "        #     X_val_ = scaler.transform(X_val)\n",
    "            \n",
    "        #     # Classifier fit / evaluate\n",
    "        #     clf.partial_fit(X_train_,Y_train,classes=classes)\n",
    "        #     acc_train_scores.append(clf.score(X_train_,Y_train))\n",
    "        #     acc_val_scores.append(clf.score(X_val_,Y_val))\n",
    "            \n",
    "        #     if acc_val_scores[-1] >= acc_val:\n",
    "        #         acc_val = acc_val_scores[-1]\n",
    "        #         best_clf = deepcopy(clf)\n",
    "        #         it_stop = it_\n",
    "        #         it_patience = 0\n",
    "        #     else: \n",
    "        #         it_patience += 1\n",
    "            \n",
    "        #     if it_patience >= patience:\n",
    "        #         break\n",
    "            \n",
    "        # X_test_ = scaler.transform(X_test)    \n",
    "        # acc_test = best_clf.score(X_test_,Y_test)\n",
    "        # acc_train = acc_train_scores[it_stop] \n",
    "        \n",
    "        # dic_aux['clf_4']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test,\n",
    "        #                 'acc_train_scores': acc_train_scores, 'acc_val_scores': acc_val_scores, 'it_stop':it_stop}\n",
    "        \n",
    "        # #-----------------------CLASSIFIER 5 -----------------------------#\n",
    "        # acc_train_scores = []\n",
    "        # acc_val_scores = []\n",
    "        # acc_train = 0\n",
    "        # acc_val = 0\n",
    "        # acc_test = 0\n",
    "        \n",
    "        # # Counter for patience\n",
    "        # it_patience = 0\n",
    "        \n",
    "        # # Best classifier in early stopping\n",
    "        # best_clf = None\n",
    "        # it_stop = 0 \n",
    "        \n",
    "        # scaler = StandardScaler()\n",
    "        # clf = MLPClassifier(hidden_layer_sizes=(10,8,3), activation='relu', solver='adam', alpha=0.0001,\n",
    "        #                     learning_rate='constant', learning_rate_init=0.01,max_iter=max_iter)\n",
    "        # classes = np.unique(Y_train)\n",
    "\n",
    "        # for it_ in range(max_iter):\n",
    "        #     # Scaler fit/transform\n",
    "        #     scaler.partial_fit(X_train, Y_train)\n",
    "        #     X_train_ = scaler.transform(X_train)\n",
    "        #     X_val_ = scaler.transform(X_val)\n",
    "            \n",
    "        #     # Classifier fit / evaluate\n",
    "        #     clf.partial_fit(X_train_,Y_train,classes=classes)\n",
    "        #     acc_train_scores.append(clf.score(X_train_,Y_train))\n",
    "        #     acc_val_scores.append(clf.score(X_val_,Y_val))\n",
    "            \n",
    "        #     if acc_val_scores[-1] >= acc_val:\n",
    "        #         acc_val = acc_val_scores[-1]\n",
    "        #         best_clf = deepcopy(clf)\n",
    "        #         it_stop = it_\n",
    "        #         it_patience = 0\n",
    "        #     else: \n",
    "        #         it_patience += 1\n",
    "            \n",
    "        #     if it_patience >= patience:\n",
    "        #         break\n",
    "            \n",
    "        # X_test_ = scaler.transform(X_test)    \n",
    "        # acc_test = best_clf.score(X_test_,Y_test)\n",
    "        # acc_train = acc_train_scores[it_stop] \n",
    "        \n",
    "        # dic_aux['clf_5']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test,\n",
    "        #                 'acc_train_scores': acc_train_scores, 'acc_val_scores': acc_val_scores, 'it_stop':it_stop}\n",
    "        \n",
    "        # #-----------------------CLASSIFIER 6 -----------------------------#\n",
    "        # acc_train_scores = []\n",
    "        # acc_val_scores = []\n",
    "        # acc_train = 0\n",
    "        # acc_val = 0\n",
    "        # acc_test = 0\n",
    "        \n",
    "        # # Counter for patience\n",
    "        # it_patience = 0\n",
    "        \n",
    "        # # Best classifier in early stopping\n",
    "        # best_clf = None\n",
    "        # it_stop = 0 \n",
    "        \n",
    "        # scaler = StandardScaler()\n",
    "        # clf = MLPClassifier(hidden_layer_sizes=(10,4,2), activation='relu', solver='adam', alpha=0.0001,\n",
    "        #                     learning_rate='constant', learning_rate_init=0.01,max_iter=max_iter)\n",
    "        # classes = np.unique(Y_train)\n",
    "\n",
    "        # for it_ in range(max_iter):\n",
    "        #     # Scaler fit/transform\n",
    "        #     scaler.partial_fit(X_train, Y_train)\n",
    "        #     X_train_ = scaler.transform(X_train)\n",
    "        #     X_val_ = scaler.transform(X_val)\n",
    "            \n",
    "        #     # Classifier fit / evaluate\n",
    "        #     clf.partial_fit(X_train_,Y_train,classes=classes)\n",
    "        #     acc_train_scores.append(clf.score(X_train_,Y_train))\n",
    "        #     acc_val_scores.append(clf.score(X_val_,Y_val))\n",
    "            \n",
    "        #     if acc_val_scores[-1] >= acc_val:\n",
    "        #         acc_val = acc_val_scores[-1]\n",
    "        #         best_clf = deepcopy(clf)\n",
    "        #         it_stop = it_\n",
    "        #         it_patience = 0\n",
    "        #     else: \n",
    "        #         it_patience += 1\n",
    "            \n",
    "        #     if it_patience >= patience:\n",
    "        #         break\n",
    "            \n",
    "        # X_test_ = scaler.transform(X_test)    \n",
    "        # acc_test = best_clf.score(X_test_,Y_test)\n",
    "        # acc_train = acc_train_scores[it_stop] \n",
    "        \n",
    "        # dic_aux['clf_6']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test,\n",
    "        #                 'acc_train_scores': acc_train_scores, 'acc_val_scores': acc_val_scores, 'it_stop':it_stop}\n",
    "        \n",
    "        info_clfs[f'fold_{it}']=dic_aux\n",
    "    info_exp[f'exp_{it_sr}'] = {'info_clfs':info_clfs, 'info_folds': info_folds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['estimator', 'acc_train', 'acc_val', 'acc_test'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_exp['exp_0']['info_clfs']['fold_0']['clf_1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos la tabla de los acc para cada iteración y clasificador\n",
    "# Generamos las tablas en el siguiente formato: EXPERIMENTOS x FOLDS x CLFs\n",
    "N_clfs = 2\n",
    "\n",
    "\n",
    "matrix_acc_train = np.zeros((N_sr,N_folds,N_clfs))\n",
    "matrix_acc_val = np.zeros((N_sr,N_folds,N_clfs))\n",
    "matrix_acc_test = np.zeros((N_sr,N_folds,N_clfs))\n",
    "\n",
    "for it0 in range(N_sr):\n",
    "    for it1 in range(N_folds):\n",
    "        for it2 in range(N_clfs):\n",
    "            matrix_acc_train[it0,it1,it2] = info_exp[f'exp_{it0}']['info_clfs'][f'fold_{it1}'][f'clf_{it2+1}']['acc_train']\n",
    "            matrix_acc_val[it0,it1,it2] = info_exp[f'exp_{it0}']['info_clfs'][f'fold_{it1}'][f'clf_{it2+1}']['acc_val']\n",
    "            matrix_acc_test[it0,it1,it2] = info_exp[f'exp_{it0}']['info_clfs'][f'fold_{it1}'][f'clf_{it2+1}']['acc_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos los datos de la corrida\n",
    "\n",
    "save_path = \"control_experiment_result.mat\"\n",
    "data_save = {}\n",
    "data_save['matrix_acc_train'] = matrix_acc_train\n",
    "data_save['matrix_acc_val'] = matrix_acc_val\n",
    "data_save['matrix_acc_test'] = matrix_acc_test\n",
    "sio.savemat(save_path, data_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducimos la dimensión de 100x20x2 a 20x2\n",
    "acc_train_mean_exps = matrix_acc_train.mean(axis=0)\n",
    "acc_train_std_exps = np.std(matrix_acc_train,axis=0)\n",
    "\n",
    "acc_val_mean_exps = matrix_acc_val.mean(axis=0)\n",
    "acc_val_std_exps = np.std(matrix_acc_val,axis=0)\n",
    "\n",
    "acc_test_mean_exps = matrix_acc_test.mean(axis=0)\n",
    "acc_test_std_exps = np.std(matrix_acc_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducimos la dimensión de 100x20x2 a 2000x2\n",
    "acc_train_exps = matrix_acc_train.reshape((2000,2))\n",
    "\n",
    "acc_val_exps = matrix_acc_val.reshape((2000,2))\n",
    "\n",
    "acc_test_exps = matrix_acc_test.reshape((2000,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_total(X):\n",
    "    # X nxr n is exps r is folds\n",
    "    var_per_group = np.var(X,axis=0)\n",
    "    mean_per_group = X.mean(axis=0)\n",
    "\n",
    "    var_2 = np.var(mean_per_group)\n",
    "    var_1 = var_per_group.mean()\n",
    "    return var_1 + var_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_mean_clfs = acc_train_mean_exps.mean(axis=0,keepdims=True)\n",
    "acc_train_std_clfs = np.expand_dims(np.array([np.sqrt(variance_total(matrix_acc_train[:,:,0])),\n",
    "                        np.sqrt(variance_total(matrix_acc_train[:,:,1]))]),axis=0)\n",
    "\n",
    "acc_val_mean_clfs = acc_val_mean_exps.mean(axis=0,keepdims=True)\n",
    "acc_val_std_clfs = np.expand_dims(np.array([np.sqrt(variance_total(matrix_acc_val[:,:,0])),\n",
    "                        np.sqrt(variance_total(matrix_acc_val[:,:,1]))]),axis=0)\n",
    "\n",
    "acc_test_mean_clfs = acc_test_mean_exps.mean(axis=0,keepdims=True)\n",
    "acc_test_std_clfs = np.expand_dims(np.array([np.sqrt(variance_total(matrix_acc_test[:,:,0])),\n",
    "                        np.sqrt(variance_total(matrix_acc_test[:,:,1]))]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN MEAN</th>\n",
       "      <th>TRAIN STD</th>\n",
       "      <th>VAL MEAN</th>\n",
       "      <th>VAL STD</th>\n",
       "      <th>TEST MEAN</th>\n",
       "      <th>TEST STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.529762</td>\n",
       "      <td>0.018271</td>\n",
       "      <td>0.515691</td>\n",
       "      <td>0.056395</td>\n",
       "      <td>0.517148</td>\n",
       "      <td>0.055479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.505087</td>\n",
       "      <td>0.032208</td>\n",
       "      <td>0.505506</td>\n",
       "      <td>0.031088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAIN MEAN  TRAIN STD  VAL MEAN   VAL STD  TEST MEAN  TEST STD\n",
       "clf_1    0.529762   0.018271  0.515691  0.056395   0.517148  0.055479\n",
       "clf_2    0.521277   0.015154  0.505087  0.032208   0.505506  0.031088"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(np.concatenate((acc_train_mean_clfs.T,acc_train_std_clfs.T,\n",
    "                                          acc_val_mean_clfs.T,acc_val_std_clfs.T,\n",
    "                                          acc_test_mean_clfs.T,acc_test_std_clfs.T),axis=1),\n",
    "                          columns = ['TRAIN MEAN', 'TRAIN STD','VAL MEAN', 'VAL STD','TEST MEAN', 'TEST STD']\n",
    "                          ,index=['clf_1','clf_2'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.519474</td>\n",
       "      <td>0.575837</td>\n",
       "      <td>0.537978</td>\n",
       "      <td>0.453679</td>\n",
       "      <td>0.548221</td>\n",
       "      <td>0.544879</td>\n",
       "      <td>0.642707</td>\n",
       "      <td>0.442724</td>\n",
       "      <td>0.502848</td>\n",
       "      <td>0.604591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562404</td>\n",
       "      <td>0.494186</td>\n",
       "      <td>0.535029</td>\n",
       "      <td>0.547570</td>\n",
       "      <td>0.429931</td>\n",
       "      <td>0.492506</td>\n",
       "      <td>0.555615</td>\n",
       "      <td>0.527136</td>\n",
       "      <td>0.431485</td>\n",
       "      <td>0.534896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.528947</td>\n",
       "      <td>0.527720</td>\n",
       "      <td>0.541645</td>\n",
       "      <td>0.486501</td>\n",
       "      <td>0.511604</td>\n",
       "      <td>0.555966</td>\n",
       "      <td>0.540399</td>\n",
       "      <td>0.440144</td>\n",
       "      <td>0.493527</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547509</td>\n",
       "      <td>0.485201</td>\n",
       "      <td>0.556305</td>\n",
       "      <td>0.539297</td>\n",
       "      <td>0.484400</td>\n",
       "      <td>0.512145</td>\n",
       "      <td>0.524599</td>\n",
       "      <td>0.495970</td>\n",
       "      <td>0.501569</td>\n",
       "      <td>0.521044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "clf_1  0.519474  0.575837  0.537978  0.453679  0.548221  0.544879  0.642707   \n",
       "clf_2  0.528947  0.527720  0.541645  0.486501  0.511604  0.555966  0.540399   \n",
       "\n",
       "           7         8         9     ...      1990      1991      1992  \\\n",
       "clf_1  0.442724  0.502848  0.604591  ...  0.562404  0.494186  0.535029   \n",
       "clf_2  0.440144  0.493527  0.535211  ...  0.547509  0.485201  0.556305   \n",
       "\n",
       "           1993      1994      1995      1996      1997      1998      1999  \n",
       "clf_1  0.547570  0.429931  0.492506  0.555615  0.527136  0.431485  0.534896  \n",
       "clf_2  0.539297  0.484400  0.512145  0.524599  0.495970  0.501569  0.521044  \n",
       "\n",
       "[2 rows x 2000 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_train_df = pd.DataFrame(acc_train_exps.T,index=['clf_1','clf_2'])\n",
    "accs_val_df = pd.DataFrame(acc_val_exps.T,index=['clf_1','clf_2'])\n",
    "accs_test_df = pd.DataFrame(acc_test_exps.T,index=['clf_1','clf_2'])\n",
    "accs_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.513978</td>\n",
       "      <td>0.513167</td>\n",
       "      <td>0.514454</td>\n",
       "      <td>0.509933</td>\n",
       "      <td>0.520072</td>\n",
       "      <td>0.506473</td>\n",
       "      <td>0.522089</td>\n",
       "      <td>0.513918</td>\n",
       "      <td>0.524312</td>\n",
       "      <td>0.531335</td>\n",
       "      <td>0.516249</td>\n",
       "      <td>0.518624</td>\n",
       "      <td>0.522903</td>\n",
       "      <td>0.519472</td>\n",
       "      <td>0.510833</td>\n",
       "      <td>0.516573</td>\n",
       "      <td>0.526778</td>\n",
       "      <td>0.521595</td>\n",
       "      <td>0.502824</td>\n",
       "      <td>0.517369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.504596</td>\n",
       "      <td>0.502711</td>\n",
       "      <td>0.505102</td>\n",
       "      <td>0.502664</td>\n",
       "      <td>0.509087</td>\n",
       "      <td>0.501406</td>\n",
       "      <td>0.507873</td>\n",
       "      <td>0.504460</td>\n",
       "      <td>0.508137</td>\n",
       "      <td>0.511949</td>\n",
       "      <td>0.506115</td>\n",
       "      <td>0.507336</td>\n",
       "      <td>0.507103</td>\n",
       "      <td>0.502463</td>\n",
       "      <td>0.503723</td>\n",
       "      <td>0.505749</td>\n",
       "      <td>0.508425</td>\n",
       "      <td>0.506222</td>\n",
       "      <td>0.498329</td>\n",
       "      <td>0.506676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "clf_1  0.513978  0.513167  0.514454  0.509933  0.520072  0.506473  0.522089   \n",
       "clf_2  0.504596  0.502711  0.505102  0.502664  0.509087  0.501406  0.507873   \n",
       "\n",
       "             7         8         9         10        11        12        13  \\\n",
       "clf_1  0.513918  0.524312  0.531335  0.516249  0.518624  0.522903  0.519472   \n",
       "clf_2  0.504460  0.508137  0.511949  0.506115  0.507336  0.507103  0.502463   \n",
       "\n",
       "             14        15        16        17        18        19  \n",
       "clf_1  0.510833  0.516573  0.526778  0.521595  0.502824  0.517369  \n",
       "clf_2  0.503723  0.505749  0.508425  0.506222  0.498329  0.506676  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_train_means_df = pd.DataFrame(acc_train_mean_exps.T,index=['clf_1','clf_2'])\n",
    "accs_val_means_df = pd.DataFrame(acc_val_mean_exps.T,index=['clf_1','clf_2'])\n",
    "accs_test_means_df = pd.DataFrame(acc_test_mean_exps.T,index=['clf_1','clf_2'])\n",
    "accs_test_means_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_1samp\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significancia: 0.025\n",
      "Intervalo de confianza: 97.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.692456</td>\n",
       "      <td>4.252646e-10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.690874</td>\n",
       "      <td>4.790560e-10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statistics       p-value     H0\n",
       "clf_1    0.692456  4.252646e-10  False\n",
       "clf_2    0.690874  4.790560e-10  False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "alpha_bonferroni = alpha / 2\n",
    "\n",
    "test_norm = pd.DataFrame(columns=['statistics','p-value','H0'])\n",
    "clf_names = accs_test_means_df.index.values.tolist()\n",
    "\n",
    "for clf in clf_names: \n",
    "    acc_test = accs_test_means_df.loc[clf]\n",
    "    norm_test = ks_1samp(acc_test,stats.norm.cdf)\n",
    "    if norm_test.pvalue <= alpha_bonferroni:\n",
    "        test_norm.loc[clf]=[norm_test.statistic,norm_test.pvalue,False]\n",
    "    else:\n",
    "        test_norm.loc[clf]=[norm_test.statistic,norm_test.pvalue,True]\n",
    "\n",
    "print(f'Significancia: {alpha_bonferroni:.2}')\n",
    "print(f'Intervalo de confianza: {100*(1-alpha_bonferroni)}')\n",
    "test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significancia: 0.025\n",
      "Intervalo de confianza: 97.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statics   p-value     H0\n",
       "clf_1      0.0  0.000002  False\n",
       "clf_2      2.0  0.000006  False"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = 0.5\n",
    "test = pd.DataFrame(columns=['statics','p-value','H0'])\n",
    "\n",
    "for clf in clf_names: \n",
    "    acc_test = accs_test_means_df.loc[clf]\n",
    "    w_test = wilcoxon(acc_test-mu)\n",
    "    if w_test.pvalue <= alpha_bonferroni:\n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,False]\n",
    "    else: \n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,True]\n",
    "\n",
    "print(f'Significancia: {alpha_bonferroni:.2}')\n",
    "print(f'Intervalo de confianza: {100*(1-alpha_bonferroni)}')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significancia: 0.025\n",
      "Intervalo de confianza: 97.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>649244.0</td>\n",
       "      <td>8.849670e-42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>734852.0</td>\n",
       "      <td>1.999913e-23</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        statics       p-value     H0\n",
       "clf_1  649244.0  8.849670e-42  False\n",
       "clf_2  734852.0  1.999913e-23  False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = 0.5\n",
    "test = pd.DataFrame(columns=['statics','p-value','H0'])\n",
    "\n",
    "for clf in clf_names: \n",
    "    acc_test = accs_test_df.loc[clf]\n",
    "    w_test = wilcoxon(acc_test-mu)\n",
    "    if w_test.pvalue <= alpha_bonferroni:\n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,False]\n",
    "    else: \n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,True]\n",
    "\n",
    "print(f'Significancia: {alpha_bonferroni:.2}')\n",
    "print(f'Intervalo de confianza: {100*(1-alpha_bonferroni)}')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('fairness1.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc5a03d0949048036a82bc8df2a1f9a734ae5fa45f6ea724030c79b47976db34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
