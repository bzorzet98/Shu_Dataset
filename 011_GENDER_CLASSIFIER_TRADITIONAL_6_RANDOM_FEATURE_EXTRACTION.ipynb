{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GroupKFold, GridSearchCV  , StratifiedGroupKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "from random import sample, shuffle\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.base import clone\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_root = \"/home/bruno/Academico/Doctorado/Neuro_Fairness/Shu_Dataset/002_Dataset_Traditional_Feature_Extraction/\"\n",
    "participants=[\"sub-001\",\"sub-002\",\"sub-003\",\"sub-004\",\"sub-005\",\n",
    "              \"sub-006\",\"sub-007\",\"sub-008\",\"sub-009\",\"sub-010\",\n",
    "              \"sub-011\",\"sub-012\",\"sub-013\",\"sub-014\",\"sub-015\",\n",
    "              \"sub-016\",\"sub-017\",\"sub-018\",\"sub-019\",\"sub-020\",\n",
    "              \"sub-021\",\"sub-022\",\"sub-023\",\"sub-024\",\"sub-025\"]\n",
    "sessions = [\"ses-01\",\"ses-02\",\"ses-03\",\"ses-04\",\"ses-05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset={}\n",
    "for participant in participants:\n",
    "    dataset[participant]={}\n",
    "    data_path=participant+\"_task_motorimagery_eeg_preprocessing_band_power_features.mat\"\n",
    "    data=sio.loadmat(dataset_path_root + data_path)\n",
    "    for session in sessions:\n",
    "        dataset[participant][session +'_data_band_power']=data[session +'_data_band_power']\n",
    "        dataset[participant][session +'_labels_trials']=data[session +'_labels_trials']\n",
    "    dataset[participant]['sfreq']=np.squeeze(data['sfreq'])\n",
    "    dataset[participant]['age']=np.squeeze(data['age'])\n",
    "    dataset[participant]['gender']=data['gender'][0]\n",
    "    dataset[participant]['group_medidator']=data['group_medidator'][0]\n",
    "    dataset[participant]['id_participant']=data['id_participant'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participantes hombres: ['sub-001', 'sub-002', 'sub-008', 'sub-012', 'sub-013', 'sub-015', 'sub-017', 'sub-018', 'sub-019', 'sub-021', 'sub-022', 'sub-023', 'sub-025']\n",
      "Participantes mujeres: ['sub-003', 'sub-004', 'sub-005', 'sub-006', 'sub-007', 'sub-009', 'sub-010', 'sub-011', 'sub-014', 'sub-016', 'sub-020', 'sub-024']\n"
     ]
    }
   ],
   "source": [
    "index_female = []\n",
    "index_male = []\n",
    "for participant in participants:\n",
    "    if dataset[participant]['gender'] == 'M':\n",
    "        index_male.append(participant)\n",
    "    elif dataset[participant]['gender'] == 'F':\n",
    "        index_female.append(participant)\n",
    "print(f\"Participantes hombres: {index_male}\")\n",
    "print(f\"Participantes mujeres: {index_female}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in participants:\n",
    "    data_ = np.concatenate((dataset[participant]['ses-01_data_band_power'],\n",
    "                            dataset[participant]['ses-02_data_band_power'],\n",
    "                            dataset[participant]['ses-03_data_band_power'],\n",
    "                            dataset[participant]['ses-04_data_band_power'],\n",
    "                            dataset[participant]['ses-05_data_band_power']),axis=0)\n",
    "    \n",
    "    dataset[participant]['data_band_power'] = data_\n",
    "    dataset[participant]['data_gender'] =  np.array(list(dataset[participant]['gender']) * data_.shape[0])\n",
    "    dataset[participant]['group_participant'] =  np.array(list([participant]) * data_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "N_it_rand = 100\n",
    "n_feature_rand = 6\n",
    "info_rand_exps = {}\n",
    "for it_rand in range(N_it_rand):\n",
    "    # Seleccionamos aleatoriamente 6 caracteristicas de cada sujeto que iran cambiando en cada iteración \n",
    "    for participant in participants:\n",
    "        X = dataset[participant]['data_band_power'].copy()\n",
    "        n_0 = X.shape[0]\n",
    "        n_1 = X.shape[1]\n",
    "        n_2 = X.shape[2]\n",
    "        X = X.reshape(n_0,n_1*n_2)\n",
    "        X_random = np.zeros((n_0,n_feature_rand))\n",
    "        for it0 in range(n_0):\n",
    "            X_random[it0,:]=sample(X[it0,:].tolist(), n_feature_rand)    \n",
    "        dataset[participant]['it_'+str(it_rand)+'_data_random'] = np.array(X_random)\n",
    "\n",
    "    n_features = data_.shape[-1]\n",
    "    N_it = 20\n",
    "    n_test_participant = 2\n",
    "    n_val_participant = 2 \n",
    "    n_ign_participant = 1\n",
    "\n",
    "    max_iter = 200\n",
    "    patience = 50\n",
    "    info_exp = {}\n",
    "    info_clfs = {}\n",
    "    #Comenzamos con el proceso de entrenamiento de los sujetos\n",
    "    for it in range(N_it):\n",
    "        dic_aux = {}\n",
    "        \n",
    "        X_train = None\n",
    "        X_val = None\n",
    "        X_test = None \n",
    "        \n",
    "        X_train_ = None\n",
    "        X_val_ = None\n",
    "        X_test_ = None\n",
    "        \n",
    "        idx_male = index_male.copy()\n",
    "        idx_female = index_female.copy()\n",
    "        \n",
    "        # TEST PARTICIPANTS:\n",
    "        idx_male_test = sample(idx_male, n_test_participant)\n",
    "        idx_female_test = sample(idx_female, n_test_participant)\n",
    "        for it_ in range(n_test_participant):\n",
    "            idx_male.remove(idx_male_test[it_])\n",
    "            idx_female.remove(idx_female_test[it_])\n",
    "        idx_test = idx_male_test + idx_female_test\n",
    "        dic_aux['reg_idx_test'] = idx_test   \n",
    "        \n",
    "        # VALIDATION PARTICIPANTS:\n",
    "        idx_male_val = sample(idx_male, n_val_participant)\n",
    "        idx_female_val = sample(idx_female, n_val_participant)\n",
    "        for it_ in range(n_val_participant):\n",
    "            idx_male.remove(idx_male_val[it_])\n",
    "            idx_female.remove(idx_female_val[it_])\n",
    "        idx_val = idx_male_val + idx_female_val\n",
    "        dic_aux['reg_idx_val'] = idx_val  \n",
    "        \n",
    "        # TRAIN PARTICIPANTS:\n",
    "        idx_male_ignore = sample(idx_male, n_ign_participant)\n",
    "        for it_ in range(n_ign_participant):\n",
    "            idx_male.remove(idx_male_ignore[it_])\n",
    "        idx_male_train = idx_male.copy()\n",
    "        idx_female_train = idx_female.copy()\n",
    "        idx_train = idx_male_train + idx_female_train\n",
    "        dic_aux['reg_idx_train'] = idx_train    \n",
    "            \n",
    "        \n",
    "        # CONCATENAMOS EL CONJUNTO DE DATOS\n",
    "        # TEST\n",
    "        X_test = np.zeros((1,n_features))\n",
    "        Y_test = np.zeros(1)\n",
    "        for participant in idx_test:\n",
    "            X_test = np.concatenate((X_test, dataset[participant]['it_'+str(it_rand)+'_data_random']),axis=0)\n",
    "            Y_test = np.concatenate((Y_test, dataset[participant]['data_gender']),axis=0)\n",
    "        X_test = X_test[1:,:]\n",
    "        Y_test = Y_test[1:]\n",
    "        dic_aux['n_trials_test'] = {'male':np.sum(Y_test == 'M'),'female':np.sum(Y_test == 'F')}\n",
    "        dic_aux['proportion_trials_test'] = {'male':np.sum(Y_test == 'M')/(np.sum(Y_test == 'M')+np.sum(Y_test == 'F')),\n",
    "                                        'female':np.sum(Y_test == 'F')/(np.sum(Y_test == 'M')+np.sum(Y_test == 'F'))}\n",
    "        # VALIDATION\n",
    "        X_val = np.zeros((1,n_features))\n",
    "        Y_val = np.zeros(1)\n",
    "        for participant in idx_val:\n",
    "            X_val = np.concatenate((X_val, dataset[participant]['it_'+str(it_rand)+'_data_random']),axis=0)\n",
    "            Y_val = np.concatenate((Y_val, dataset[participant]['data_gender']),axis=0)\n",
    "        X_val = X_val[1:,:]\n",
    "        Y_val = Y_val[1:]\n",
    "        dic_aux['n_trials_val'] = {'male':np.sum(Y_val == 'M'),'female':np.sum(Y_val == 'F')}\n",
    "        dic_aux['proportion_trials_val'] = {'male':np.sum(Y_val == 'M')/(np.sum(Y_val == 'M')+np.sum(Y_val == 'F')),\n",
    "                                        'female':np.sum(Y_val == 'F')/(np.sum(Y_val == 'M')+np.sum(Y_val == 'F'))}\n",
    "            \n",
    "        # TRAIN\n",
    "        X_train = np.zeros((1,n_features))\n",
    "        Y_train = np.zeros(1)\n",
    "        for participant in idx_train:\n",
    "            X_train = np.concatenate((X_train, dataset[participant]['it_'+str(it_rand)+'_data_random']),axis=0)\n",
    "            Y_train = np.concatenate((Y_train, dataset[participant]['data_gender']),axis=0)\n",
    "        X_train = X_train[1:,:]\n",
    "        Y_train = Y_train[1:]\n",
    "        dic_aux['n_trials_train'] = {'male':np.sum(Y_train == 'M'),'female':np.sum(Y_train == 'F')}\n",
    "        dic_aux['proportion_trials_train'] = {'male':np.sum(Y_train == 'M')/(np.sum(Y_train == 'M')+np.sum(Y_train == 'F')),\n",
    "                                        'female':np.sum(Y_train == 'F')/(np.sum(Y_train == 'M')+np.sum(Y_train == 'F'))}   \n",
    "        \n",
    "        info_exp[f'it_{it}']=dic_aux\n",
    "        \n",
    "        dic_aux={}\n",
    "        \n",
    "        #-----------------------CLASSIFIER 1 -----------------------------#\n",
    "        acc_train = None\n",
    "        acc_val = None\n",
    "        acc_test = None\n",
    "        \n",
    "        tol = 1e-4\n",
    "        scaler = StandardScaler()\n",
    "        clf = LinearDiscriminantAnalysis(tol=tol)\n",
    "        \n",
    "        X_train_ = scaler.fit_transform(X_train, Y_train)\n",
    "        X_val_ = scaler.transform(X_val)\n",
    "        X_test_ = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        clf.fit(X_train_, Y_train)\n",
    "        acc_train = clf.score(X_train_ , Y_train)\n",
    "        acc_val = clf.score(X_val_ , Y_val)\n",
    "        acc_test = clf.score(X_test_, Y_test)\n",
    "        \n",
    "        dic_aux['clf_1']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test}\n",
    "        info_clfs[f'it_{it}']=dic_aux\n",
    "        \n",
    "    info_rand_exps[f'random_sample_{it_rand}'] = {'info_clfs': info_clfs , 'info_exp': info_exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos la tabla de los acc para cada iteración y clasificador\n",
    "n_clfs = 1\n",
    "\n",
    "matrix_acc_train = np.zeros((N_it_rand,n_clfs,N_it))\n",
    "matrix_acc_val = np.zeros((N_it_rand,n_clfs,N_it))\n",
    "matrix_acc_test = np.zeros((N_it_rand,n_clfs,N_it))\n",
    "\n",
    "for it_rand in range(N_it_rand): \n",
    "    for it1 in range(n_clfs):\n",
    "        for it0 in range(N_it):\n",
    "            matrix_acc_train[it_rand,it1,it0] = info_rand_exps[f'random_sample_{it_rand}']['info_clfs'][f'it_{it0}'][f'clf_{it1+1}']['acc_train']\n",
    "            matrix_acc_val[it_rand,it1,it0] = info_rand_exps[f'random_sample_{it_rand}']['info_clfs'][f'it_{it0}'][f'clf_{it1+1}']['acc_val']\n",
    "            matrix_acc_test[it_rand,it1,it0] = info_rand_exps[f'random_sample_{it_rand}']['info_clfs'][f'it_{it0}'][f'clf_{it1+1}']['acc_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_clfs_mean = matrix_acc_train.mean(axis=2,keepdims=False)\n",
    "acc_train_clfs_std = np.std(matrix_acc_train,axis=2,keepdims=False)\n",
    "\n",
    "acc_val_clfs_mean = matrix_acc_val.mean(axis=2,keepdims=False)\n",
    "acc_val_clfs_std = np.std(matrix_acc_val,axis=2,keepdims=False)\n",
    "\n",
    "acc_test_clfs_mean = matrix_acc_test.mean(axis=2,keepdims=False)\n",
    "acc_test_clfs_std = np.std(matrix_acc_test,axis=2,keepdims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_sample_0</th>\n",
       "      <td>0.380903</td>\n",
       "      <td>0.497054</td>\n",
       "      <td>0.531136</td>\n",
       "      <td>0.507405</td>\n",
       "      <td>0.515469</td>\n",
       "      <td>0.465855</td>\n",
       "      <td>0.442894</td>\n",
       "      <td>0.465128</td>\n",
       "      <td>0.462349</td>\n",
       "      <td>0.536885</td>\n",
       "      <td>0.426433</td>\n",
       "      <td>0.543684</td>\n",
       "      <td>0.623012</td>\n",
       "      <td>0.509732</td>\n",
       "      <td>0.578504</td>\n",
       "      <td>0.467717</td>\n",
       "      <td>0.565672</td>\n",
       "      <td>0.502343</td>\n",
       "      <td>0.592316</td>\n",
       "      <td>0.515767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.514345</td>\n",
       "      <td>0.493886</td>\n",
       "      <td>0.491829</td>\n",
       "      <td>0.487138</td>\n",
       "      <td>0.510980</td>\n",
       "      <td>0.495996</td>\n",
       "      <td>0.563278</td>\n",
       "      <td>0.492047</td>\n",
       "      <td>0.546262</td>\n",
       "      <td>0.532167</td>\n",
       "      <td>0.556739</td>\n",
       "      <td>0.469430</td>\n",
       "      <td>0.535173</td>\n",
       "      <td>0.434089</td>\n",
       "      <td>0.643799</td>\n",
       "      <td>0.510109</td>\n",
       "      <td>0.463996</td>\n",
       "      <td>0.567869</td>\n",
       "      <td>0.542722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_2</th>\n",
       "      <td>0.459877</td>\n",
       "      <td>0.604156</td>\n",
       "      <td>0.555324</td>\n",
       "      <td>0.513247</td>\n",
       "      <td>0.497012</td>\n",
       "      <td>0.548793</td>\n",
       "      <td>0.497667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.568353</td>\n",
       "      <td>0.569755</td>\n",
       "      <td>0.557823</td>\n",
       "      <td>0.580240</td>\n",
       "      <td>0.444503</td>\n",
       "      <td>0.561348</td>\n",
       "      <td>0.454116</td>\n",
       "      <td>0.563801</td>\n",
       "      <td>0.619530</td>\n",
       "      <td>0.436583</td>\n",
       "      <td>0.476140</td>\n",
       "      <td>0.529289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_3</th>\n",
       "      <td>0.507878</td>\n",
       "      <td>0.592056</td>\n",
       "      <td>0.456961</td>\n",
       "      <td>0.509313</td>\n",
       "      <td>0.524142</td>\n",
       "      <td>0.513395</td>\n",
       "      <td>0.548705</td>\n",
       "      <td>0.455394</td>\n",
       "      <td>0.588963</td>\n",
       "      <td>0.517634</td>\n",
       "      <td>0.580343</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.539537</td>\n",
       "      <td>0.367601</td>\n",
       "      <td>0.519168</td>\n",
       "      <td>0.505664</td>\n",
       "      <td>0.470315</td>\n",
       "      <td>0.547744</td>\n",
       "      <td>0.483218</td>\n",
       "      <td>0.534097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_4</th>\n",
       "      <td>0.509969</td>\n",
       "      <td>0.491357</td>\n",
       "      <td>0.469103</td>\n",
       "      <td>0.610735</td>\n",
       "      <td>0.534982</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>0.506548</td>\n",
       "      <td>0.446130</td>\n",
       "      <td>0.484310</td>\n",
       "      <td>0.532835</td>\n",
       "      <td>0.612593</td>\n",
       "      <td>0.474774</td>\n",
       "      <td>0.499474</td>\n",
       "      <td>0.505670</td>\n",
       "      <td>0.460978</td>\n",
       "      <td>0.576803</td>\n",
       "      <td>0.567711</td>\n",
       "      <td>0.539530</td>\n",
       "      <td>0.597164</td>\n",
       "      <td>0.545360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_95</th>\n",
       "      <td>0.442501</td>\n",
       "      <td>0.479666</td>\n",
       "      <td>0.574682</td>\n",
       "      <td>0.535733</td>\n",
       "      <td>0.561543</td>\n",
       "      <td>0.454876</td>\n",
       "      <td>0.568387</td>\n",
       "      <td>0.507758</td>\n",
       "      <td>0.560331</td>\n",
       "      <td>0.489440</td>\n",
       "      <td>0.497371</td>\n",
       "      <td>0.552859</td>\n",
       "      <td>0.553125</td>\n",
       "      <td>0.514493</td>\n",
       "      <td>0.445493</td>\n",
       "      <td>0.501832</td>\n",
       "      <td>0.475506</td>\n",
       "      <td>0.561792</td>\n",
       "      <td>0.492348</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_96</th>\n",
       "      <td>0.460145</td>\n",
       "      <td>0.406364</td>\n",
       "      <td>0.557802</td>\n",
       "      <td>0.530890</td>\n",
       "      <td>0.595645</td>\n",
       "      <td>0.479619</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.528639</td>\n",
       "      <td>0.452899</td>\n",
       "      <td>0.534145</td>\n",
       "      <td>0.516535</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>0.593880</td>\n",
       "      <td>0.523061</td>\n",
       "      <td>0.459764</td>\n",
       "      <td>0.479915</td>\n",
       "      <td>0.422954</td>\n",
       "      <td>0.570466</td>\n",
       "      <td>0.525226</td>\n",
       "      <td>0.428497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_97</th>\n",
       "      <td>0.470206</td>\n",
       "      <td>0.482059</td>\n",
       "      <td>0.518384</td>\n",
       "      <td>0.465455</td>\n",
       "      <td>0.404343</td>\n",
       "      <td>0.495065</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.498446</td>\n",
       "      <td>0.557489</td>\n",
       "      <td>0.552824</td>\n",
       "      <td>0.454074</td>\n",
       "      <td>0.540773</td>\n",
       "      <td>0.480624</td>\n",
       "      <td>0.547631</td>\n",
       "      <td>0.499463</td>\n",
       "      <td>0.555732</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.482415</td>\n",
       "      <td>0.548337</td>\n",
       "      <td>0.418058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_98</th>\n",
       "      <td>0.458422</td>\n",
       "      <td>0.470558</td>\n",
       "      <td>0.586702</td>\n",
       "      <td>0.488008</td>\n",
       "      <td>0.562967</td>\n",
       "      <td>0.505523</td>\n",
       "      <td>0.480302</td>\n",
       "      <td>0.585495</td>\n",
       "      <td>0.617143</td>\n",
       "      <td>0.444504</td>\n",
       "      <td>0.617428</td>\n",
       "      <td>0.607462</td>\n",
       "      <td>0.465453</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.503896</td>\n",
       "      <td>0.634555</td>\n",
       "      <td>0.550155</td>\n",
       "      <td>0.524948</td>\n",
       "      <td>0.488755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_99</th>\n",
       "      <td>0.567596</td>\n",
       "      <td>0.513911</td>\n",
       "      <td>0.488458</td>\n",
       "      <td>0.549428</td>\n",
       "      <td>0.511170</td>\n",
       "      <td>0.663712</td>\n",
       "      <td>0.484707</td>\n",
       "      <td>0.506062</td>\n",
       "      <td>0.561079</td>\n",
       "      <td>0.537984</td>\n",
       "      <td>0.552995</td>\n",
       "      <td>0.515560</td>\n",
       "      <td>0.585933</td>\n",
       "      <td>0.546359</td>\n",
       "      <td>0.630721</td>\n",
       "      <td>0.523610</td>\n",
       "      <td>0.533402</td>\n",
       "      <td>0.435669</td>\n",
       "      <td>0.587260</td>\n",
       "      <td>0.494430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5   \\\n",
       "random_sample_0   0.380903  0.497054  0.531136  0.507405  0.515469  0.465855   \n",
       "random_sample_1   0.500000  0.514345  0.493886  0.491829  0.487138  0.510980   \n",
       "random_sample_2   0.459877  0.604156  0.555324  0.513247  0.497012  0.548793   \n",
       "random_sample_3   0.507878  0.592056  0.456961  0.509313  0.524142  0.513395   \n",
       "random_sample_4   0.509969  0.491357  0.469103  0.610735  0.534982  0.364583   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "random_sample_95  0.442501  0.479666  0.574682  0.535733  0.561543  0.454876   \n",
       "random_sample_96  0.460145  0.406364  0.557802  0.530890  0.595645  0.479619   \n",
       "random_sample_97  0.470206  0.482059  0.518384  0.465455  0.404343  0.495065   \n",
       "random_sample_98  0.458422  0.470558  0.586702  0.488008  0.562967  0.505523   \n",
       "random_sample_99  0.567596  0.513911  0.488458  0.549428  0.511170  0.663712   \n",
       "\n",
       "                        6         7         8         9         10        11  \\\n",
       "random_sample_0   0.442894  0.465128  0.462349  0.536885  0.426433  0.543684   \n",
       "random_sample_1   0.495996  0.563278  0.492047  0.546262  0.532167  0.556739   \n",
       "random_sample_2   0.497667  0.500000  0.568353  0.569755  0.557823  0.580240   \n",
       "random_sample_3   0.548705  0.455394  0.588963  0.517634  0.580343  0.573529   \n",
       "random_sample_4   0.506548  0.446130  0.484310  0.532835  0.612593  0.474774   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "random_sample_95  0.568387  0.507758  0.560331  0.489440  0.497371  0.552859   \n",
       "random_sample_96  0.511278  0.528639  0.452899  0.534145  0.516535  0.460526   \n",
       "random_sample_97  0.641026  0.498446  0.557489  0.552824  0.454074  0.540773   \n",
       "random_sample_98  0.480302  0.585495  0.617143  0.444504  0.617428  0.607462   \n",
       "random_sample_99  0.484707  0.506062  0.561079  0.537984  0.552995  0.515560   \n",
       "\n",
       "                        12        13        14        15        16        17  \\\n",
       "random_sample_0   0.623012  0.509732  0.578504  0.467717  0.565672  0.502343   \n",
       "random_sample_1   0.469430  0.535173  0.434089  0.643799  0.510109  0.463996   \n",
       "random_sample_2   0.444503  0.561348  0.454116  0.563801  0.619530  0.436583   \n",
       "random_sample_3   0.539537  0.367601  0.519168  0.505664  0.470315  0.547744   \n",
       "random_sample_4   0.499474  0.505670  0.460978  0.576803  0.567711  0.539530   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "random_sample_95  0.553125  0.514493  0.445493  0.501832  0.475506  0.561792   \n",
       "random_sample_96  0.593880  0.523061  0.459764  0.479915  0.422954  0.570466   \n",
       "random_sample_97  0.480624  0.547631  0.499463  0.555732  0.493506  0.482415   \n",
       "random_sample_98  0.465453  0.520000  0.482456  0.503896  0.634555  0.550155   \n",
       "random_sample_99  0.585933  0.546359  0.630721  0.523610  0.533402  0.435669   \n",
       "\n",
       "                        18        19  \n",
       "random_sample_0   0.592316  0.515767  \n",
       "random_sample_1   0.567869  0.542722  \n",
       "random_sample_2   0.476140  0.529289  \n",
       "random_sample_3   0.483218  0.534097  \n",
       "random_sample_4   0.597164  0.545360  \n",
       "...                    ...       ...  \n",
       "random_sample_95  0.492348  0.586207  \n",
       "random_sample_96  0.525226  0.428497  \n",
       "random_sample_97  0.548337  0.418058  \n",
       "random_sample_98  0.524948  0.488755  \n",
       "random_sample_99  0.587260  0.494430  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps_random_list =  [f'random_sample_{it_rand}' for it_rand in range(N_it_rand)]\n",
    "accs_train_df = pd.DataFrame(np.squeeze(matrix_acc_train),index=exps_random_list)\n",
    "accs_val_df = pd.DataFrame(np.squeeze(matrix_acc_val),index=exps_random_list)\n",
    "accs_test_df = pd.DataFrame(np.squeeze(matrix_acc_test),index=exps_random_list)\n",
    "accs_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN MEAN</th>\n",
       "      <th>TRAIN STD</th>\n",
       "      <th>VAL MEAN</th>\n",
       "      <th>VAL STD</th>\n",
       "      <th>TEST MEAN</th>\n",
       "      <th>TEST STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_sample_0</th>\n",
       "      <td>0.530458</td>\n",
       "      <td>0.017821</td>\n",
       "      <td>0.539334</td>\n",
       "      <td>0.042135</td>\n",
       "      <td>0.506513</td>\n",
       "      <td>0.057389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_1</th>\n",
       "      <td>0.531759</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>0.523889</td>\n",
       "      <td>0.057537</td>\n",
       "      <td>0.517593</td>\n",
       "      <td>0.044670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_2</th>\n",
       "      <td>0.529237</td>\n",
       "      <td>0.014525</td>\n",
       "      <td>0.496982</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.526878</td>\n",
       "      <td>0.052781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_3</th>\n",
       "      <td>0.531574</td>\n",
       "      <td>0.017251</td>\n",
       "      <td>0.515173</td>\n",
       "      <td>0.056229</td>\n",
       "      <td>0.516783</td>\n",
       "      <td>0.052034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_4</th>\n",
       "      <td>0.531157</td>\n",
       "      <td>0.019084</td>\n",
       "      <td>0.512229</td>\n",
       "      <td>0.054170</td>\n",
       "      <td>0.516530</td>\n",
       "      <td>0.059232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_95</th>\n",
       "      <td>0.531612</td>\n",
       "      <td>0.017690</td>\n",
       "      <td>0.525247</td>\n",
       "      <td>0.059099</td>\n",
       "      <td>0.517797</td>\n",
       "      <td>0.044310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_96</th>\n",
       "      <td>0.536835</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.509008</td>\n",
       "      <td>0.053274</td>\n",
       "      <td>0.501913</td>\n",
       "      <td>0.054001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_97</th>\n",
       "      <td>0.528791</td>\n",
       "      <td>0.014654</td>\n",
       "      <td>0.512503</td>\n",
       "      <td>0.038988</td>\n",
       "      <td>0.505296</td>\n",
       "      <td>0.053040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_98</th>\n",
       "      <td>0.527939</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.537239</td>\n",
       "      <td>0.049268</td>\n",
       "      <td>0.529737</td>\n",
       "      <td>0.059029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_99</th>\n",
       "      <td>0.526814</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.512336</td>\n",
       "      <td>0.033129</td>\n",
       "      <td>0.539502</td>\n",
       "      <td>0.050808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TRAIN MEAN  TRAIN STD  VAL MEAN   VAL STD  TEST MEAN  \\\n",
       "random_sample_0     0.530458   0.017821  0.539334  0.042135   0.506513   \n",
       "random_sample_1     0.531759   0.017722  0.523889  0.057537   0.517593   \n",
       "random_sample_2     0.529237   0.014525  0.496982  0.055215   0.526878   \n",
       "random_sample_3     0.531574   0.017251  0.515173  0.056229   0.516783   \n",
       "random_sample_4     0.531157   0.019084  0.512229  0.054170   0.516530   \n",
       "...                      ...        ...       ...       ...        ...   \n",
       "random_sample_95    0.531612   0.017690  0.525247  0.059099   0.517797   \n",
       "random_sample_96    0.536835   0.021398  0.509008  0.053274   0.501913   \n",
       "random_sample_97    0.528791   0.014654  0.512503  0.038988   0.505296   \n",
       "random_sample_98    0.527939   0.015236  0.537239  0.049268   0.529737   \n",
       "random_sample_99    0.526814   0.011200  0.512336  0.033129   0.539502   \n",
       "\n",
       "                  TEST STD  \n",
       "random_sample_0   0.057389  \n",
       "random_sample_1   0.044670  \n",
       "random_sample_2   0.052781  \n",
       "random_sample_3   0.052034  \n",
       "random_sample_4   0.059232  \n",
       "...                    ...  \n",
       "random_sample_95  0.044310  \n",
       "random_sample_96  0.054001  \n",
       "random_sample_97  0.053040  \n",
       "random_sample_98  0.059029  \n",
       "random_sample_99  0.050808  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(np.concatenate((acc_train_clfs_mean,acc_train_clfs_std,\n",
    "                                          acc_val_clfs_mean,acc_val_clfs_std,\n",
    "                                          acc_test_clfs_mean,acc_test_clfs_std),axis=1),\n",
    "                          columns = ['TRAIN MEAN', 'TRAIN STD','VAL MEAN', 'VAL STD','TEST MEAN', 'TEST STD']\n",
    "                          ,index=exps_random_list)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_1samp\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significancia: 0.0005\n",
      "Intervalo de confianza: 99.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_sample_0</th>\n",
       "      <td>0.648362</td>\n",
       "      <td>9.766425e-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_1</th>\n",
       "      <td>0.667888</td>\n",
       "      <td>2.552574e-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_2</th>\n",
       "      <td>0.668793</td>\n",
       "      <td>2.394531e-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_3</th>\n",
       "      <td>0.643415</td>\n",
       "      <td>1.357322e-08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_4</th>\n",
       "      <td>0.642289</td>\n",
       "      <td>1.462025e-08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_95</th>\n",
       "      <td>0.670937</td>\n",
       "      <td>2.056859e-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_96</th>\n",
       "      <td>0.657762</td>\n",
       "      <td>5.163683e-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_97</th>\n",
       "      <td>0.657020</td>\n",
       "      <td>5.433454e-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_98</th>\n",
       "      <td>0.671661</td>\n",
       "      <td>1.953524e-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_99</th>\n",
       "      <td>0.668462</td>\n",
       "      <td>2.451260e-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  statistics       p-value     H0\n",
       "random_sample_0     0.648362  9.766425e-09  False\n",
       "random_sample_1     0.667888  2.552574e-09  False\n",
       "random_sample_2     0.668793  2.394531e-09  False\n",
       "random_sample_3     0.643415  1.357322e-08  False\n",
       "random_sample_4     0.642289  1.462025e-08  False\n",
       "...                      ...           ...    ...\n",
       "random_sample_95    0.670937  2.056859e-09  False\n",
       "random_sample_96    0.657762  5.163683e-09  False\n",
       "random_sample_97    0.657020  5.433454e-09  False\n",
       "random_sample_98    0.671661  1.953524e-09  False\n",
       "random_sample_99    0.668462  2.451260e-09  False\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "alpha_bonferroni = alpha / 100\n",
    "\n",
    "test_norm = pd.DataFrame(columns=['statistics','p-value','H0'])\n",
    "clf_names = accs_test_df.index.values.tolist()\n",
    "\n",
    "for clf in clf_names: \n",
    "    acc_test = accs_test_df.loc[clf]\n",
    "    norm_test = ks_1samp(acc_test,stats.norm.cdf)\n",
    "    if norm_test.pvalue <= alpha_bonferroni:\n",
    "        test_norm.loc[clf]=[norm_test.statistic,norm_test.pvalue,False]\n",
    "    else:\n",
    "        test_norm.loc[clf]=[norm_test.statistic,norm_test.pvalue,True]\n",
    "\n",
    "print(f'Significancia: {alpha_bonferroni:.2}')\n",
    "print(f'Intervalo de confianza: {100*(1-alpha_bonferroni)}')\n",
    "test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/anaconda3/envs/fairness1.0/lib/python3.10/site-packages/scipy/stats/_morestats.py:3255: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/bruno/anaconda3/envs/fairness1.0/lib/python3.10/site-packages/scipy/stats/_morestats.py:3255: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/bruno/anaconda3/envs/fairness1.0/lib/python3.10/site-packages/scipy/stats/_morestats.py:3255: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significancia: 0.0005\n",
      "Intervalo de confianza: 99.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/anaconda3/envs/fairness1.0/lib/python3.10/site-packages/scipy/stats/_morestats.py:3255: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_sample_0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.595819</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.107466</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_2</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.036385</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_3</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.089695</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_4</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.216167</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_95</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.113987</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_96</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.985435</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>0.784126</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_98</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.105398</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_99</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  statics   p-value    H0\n",
       "random_sample_0      90.0  0.595819  True\n",
       "random_sample_1      55.0  0.107466  True\n",
       "random_sample_2      43.0  0.036385  True\n",
       "random_sample_3      59.0  0.089695  True\n",
       "random_sample_4      71.0  0.216167  True\n",
       "...                   ...       ...   ...\n",
       "random_sample_95     62.0  0.113987  True\n",
       "random_sample_96    104.0  0.985435  True\n",
       "random_sample_97     97.0  0.784126  True\n",
       "random_sample_98     61.0  0.105398  True\n",
       "random_sample_99     26.0  0.001986  True\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = 0.5\n",
    "test = pd.DataFrame(columns=['statics','p-value','H0'])\n",
    "\n",
    "for clf in clf_names: \n",
    "    acc_test = accs_test_df.loc[clf]\n",
    "    w_test = wilcoxon(acc_test-mu)\n",
    "    if w_test.pvalue <= alpha_bonferroni:\n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,False]\n",
    "    else: \n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,True]\n",
    "\n",
    "print(f'Significancia: {alpha_bonferroni:.2}')\n",
    "print(f'Intervalo de confianza: {100*(1-alpha_bonferroni)}')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_sample_29</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_68</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sample_82</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  statics   p-value     H0\n",
       "random_sample_29     17.0  0.000395  False\n",
       "random_sample_68      7.0  0.000036  False\n",
       "random_sample_82      7.0  0.000036  False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['H0'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairness1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9719b890ea8a12de661beec7aeb70bb889ba79a664a03946a3ab2704cb94260"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
