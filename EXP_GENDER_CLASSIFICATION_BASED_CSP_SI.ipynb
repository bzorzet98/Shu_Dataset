{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy import signal\n",
    "\n",
    "from random import sample, shuffle\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GroupKFold, GridSearchCV  , StratifiedGroupKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from mne.decoding import CSP\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_root = \"/home/bruno/Academico/Doctorado/Neuro_Fairness/Shu_Dataset/000_Dataset_Preprocessing/\"\n",
    "#dataset_path_root = \"/home/bzorzet/Academico/Neuro_Fairness/Shu_Dataset/000_Dataset_Preprocessing/\"\n",
    "participants=[\"sub-001\",\"sub-002\",\"sub-003\",\"sub-004\",\"sub-005\",\n",
    "              \"sub-006\",\"sub-007\",\"sub-008\",\"sub-009\",\"sub-010\",\n",
    "              \"sub-011\",\"sub-012\",\"sub-013\",\"sub-014\",\"sub-015\",\n",
    "              \"sub-016\",\"sub-017\",\"sub-018\",\"sub-019\",\"sub-020\",\n",
    "              \"sub-021\",\"sub-022\",\"sub-023\",\"sub-024\",\"sub-025\"]\n",
    "sessions = [\"ses-01\",\"ses-02\",\"ses-03\",\"ses-04\",\"ses-05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset={}\n",
    "for participant in participants:\n",
    "    flag_participant=True\n",
    "    dataset[participant]={}\n",
    "    for session in sessions: \n",
    "        database_path= dataset_path_root + participant +\"/\"\n",
    "        data_path=participant+\"_\"+session+\"_task_motorimagery_eeg_preprocessing.mat\"\n",
    "        data=sio.loadmat(database_path + data_path)\n",
    "\n",
    "        dataset[participant][session]= {}\n",
    "        dataset[participant][session]['data'] = data['data']\n",
    "        dataset[participant][session]['labels_trials'] = np.squeeze(data['labels_trials'])\n",
    "        dataset[participant][session]['n_epochs'] = data['data'].shape[0]\n",
    "        dataset[participant][session]['n_samples'] = data['data'].shape[2]\n",
    "        dataset[participant][session]['n_chans'] = data['data'].shape[1]\n",
    "\n",
    "        if flag_participant and session == sessions[-1]:\n",
    "            dataset[participant]['group_medidator'] = data['group_medidator']\n",
    "            dataset[participant]['gender'] = data['gender']\n",
    "            dataset[participant]['id_participant'] = data['id_participant']\n",
    "            dataset[participant]['sfreq'] = data['sfreq']\n",
    "            ch_names = data['ch_names']\n",
    "            it=0\n",
    "            for ch in data['ch_names']:\n",
    "                if ' ' in ch:\n",
    "                    ch_names[it]=ch[:-1]\n",
    "                it+=1\n",
    "            dataset[participant]['ch_names']=ch_names \n",
    "            dataset[participant]['age'] = data['age']\n",
    "            flag_participant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ses-01', 'ses-02', 'ses-03', 'ses-04', 'ses-05', 'group_medidator', 'gender', 'id_participant', 'sfreq', 'ch_names', 'age'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[participant].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos las sesiones de los sujetos\n",
    "nchan = dataset[participant][session]['n_chans']\n",
    "nsamples = dataset[participant][session]['n_samples']\n",
    "\n",
    "for participant in participants:\n",
    "    data_=np.zeros((1,nchan,nsamples))\n",
    "    labels_=np.zeros((1))\n",
    "    for session in sessions: \n",
    "        data_ = np.concatenate((data_, dataset[participant][session]['data']),axis=0)\n",
    "        labels_ = np.concatenate((labels_, dataset[participant][session]['labels_trials']),axis=0)\n",
    "    data_ = data_[1:,:,:]\n",
    "    labels_ = labels_[1:]\n",
    "    \n",
    "    dataset[participant]['data_sessions'] = data_.copy()\n",
    "    dataset[participant]['labels_sessions'] = labels_.copy()\n",
    "    dataset[participant]['data_gender'] =  np.array(list(dataset[participant]['gender']) * data_.shape[0])\n",
    "    dataset[participant]['group_participant'] =  np.array(list([participant]) * data_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participantes hombres: ['sub-001', 'sub-002', 'sub-008', 'sub-012', 'sub-013', 'sub-015', 'sub-017', 'sub-018', 'sub-019', 'sub-021', 'sub-022', 'sub-023', 'sub-025']\n",
      "Participantes mujeres: ['sub-003', 'sub-004', 'sub-005', 'sub-006', 'sub-007', 'sub-009', 'sub-010', 'sub-011', 'sub-014', 'sub-016', 'sub-020', 'sub-024']\n"
     ]
    }
   ],
   "source": [
    "index_female = []\n",
    "index_male = []\n",
    "for participant in participants:\n",
    "    if dataset[participant]['gender'] == 'M':\n",
    "        index_male.append(participant)\n",
    "    elif dataset[participant]['gender'] == 'F':\n",
    "        index_female.append(participant)\n",
    "print(f\"Participantes hombres: {index_male}\")\n",
    "print(f\"Participantes mujeres: {index_female}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "n_features = 6\n",
    "N_it = 20\n",
    "n_test_participant = 2\n",
    "n_val_participant = 2 \n",
    "n_ign_participant = 1\n",
    "\n",
    "max_iter = 200\n",
    "patience = 50 \n",
    "info_exp = {}\n",
    "info_clfs = {}\n",
    "for it in range(N_it):\n",
    "    dic_aux = {}\n",
    "    \n",
    "    X_train = None\n",
    "    X_val = None\n",
    "    X_test = None \n",
    "    \n",
    "    X_train_ = None\n",
    "    X_val_ = None\n",
    "    X_test_ = None\n",
    "    \n",
    "    idx_male = index_male.copy()\n",
    "    idx_female = index_female.copy()\n",
    "    # DIVIDE DATASET IN TRAIN, TEST AND VAL\n",
    "    # TEST PARTICIPANTS:\n",
    "    idx_male_test = sample(idx_male, n_test_participant)\n",
    "    idx_female_test = sample(idx_female, n_test_participant)\n",
    "    for it_ in range(n_test_participant):\n",
    "        idx_male.remove(idx_male_test[it_])\n",
    "        idx_female.remove(idx_female_test[it_])\n",
    "    idx_test = idx_male_test + idx_female_test\n",
    "    dic_aux['reg_idx_test'] = idx_test   \n",
    "    # VALIDATION PARTICIPANTS:\n",
    "    idx_male_val = sample(idx_male, n_val_participant)\n",
    "    idx_female_val = sample(idx_female, n_val_participant)\n",
    "    for it_ in range(n_val_participant):\n",
    "        idx_male.remove(idx_male_val[it_])\n",
    "        idx_female.remove(idx_female_val[it_])\n",
    "    idx_val = idx_male_val + idx_female_val\n",
    "    dic_aux['reg_idx_val'] = idx_val  \n",
    "    # TRAIN PARTICIPANTS:\n",
    "    idx_male_ignore = sample(idx_male, n_ign_participant)\n",
    "    for it_ in range(n_ign_participant):\n",
    "        idx_male.remove(idx_male_ignore[it_])\n",
    "    idx_male_train = idx_male.copy()\n",
    "    idx_female_train = idx_female.copy()\n",
    "    idx_train = idx_male_train + idx_female_train\n",
    "    dic_aux['reg_idx_train'] = idx_train\n",
    "\n",
    "\n",
    "    # CONCATENAMOS EL CONJUNTO DE DATOS\n",
    "    # TRAIN \n",
    "    X_train = np.zeros((1,nchan,nsamples))\n",
    "    Y_train = np.zeros(1)\n",
    "    labels_train = np.zeros(1)\n",
    "    for participant in idx_train:\n",
    "        X_train = np.concatenate((X_train, dataset[participant]['data_sessions']),axis=0)\n",
    "        Y_train = np.concatenate((Y_train, dataset[participant]['data_gender']),axis=0)\n",
    "        labels_train = np.concatenate((labels_train, dataset[participant]['labels_sessions']),axis=0)\n",
    "    X_train = X_train[1:,:]\n",
    "    Y_train = Y_train[1:]\n",
    "    labels_train = labels_train[1:]\n",
    "    dic_aux['n_trials_train'] = {'male':np.sum(Y_train == 'M'),'female':np.sum(Y_train == 'F')}\n",
    "    dic_aux['proportion_trials_train'] = {'male':np.sum(Y_train == 'M')/(np.sum(Y_train == 'M')+np.sum(Y_train == 'F')),\n",
    "                                      'female':np.sum(Y_train == 'F')/(np.sum(Y_train == 'M')+np.sum(Y_train == 'F'))}   \n",
    "    \n",
    "    # TEST\n",
    "    X_test = np.zeros((1,nchan,nsamples))\n",
    "    Y_test = np.zeros(1)\n",
    "    labels_test = np.zeros(1)\n",
    "    for participant in idx_test:\n",
    "        X_test = np.concatenate((X_test, dataset[participant]['data_sessions']),axis=0)\n",
    "        Y_test = np.concatenate((Y_test, dataset[participant]['data_gender']),axis=0)\n",
    "        labels_test = np.concatenate((labels_test, dataset[participant]['labels_sessions']),axis=0)\n",
    "    X_test = X_test[1:,:]\n",
    "    Y_test = Y_test[1:]\n",
    "    labels_test = labels_test[1:]\n",
    "    dic_aux['n_trials_test'] = {'male':np.sum(Y_test == 'M'),'female':np.sum(Y_test == 'F')}\n",
    "    dic_aux['proportion_trials_test'] = {'male':np.sum(Y_test == 'M')/(np.sum(Y_test == 'M')+np.sum(Y_test == 'F')),\n",
    "                                      'female':np.sum(Y_test == 'F')/(np.sum(Y_test == 'M')+np.sum(Y_test == 'F'))}\n",
    "    # VALIDATION\n",
    "    X_val = np.zeros((1,nchan,nsamples))\n",
    "    Y_val = np.zeros(1)\n",
    "    labels_val = np.zeros(1)\n",
    "    for participant in idx_val:\n",
    "        X_val = np.concatenate((X_val, dataset[participant]['data_sessions']),axis=0)\n",
    "        Y_val = np.concatenate((Y_val, dataset[participant]['data_gender']),axis=0)\n",
    "        labels_val = np.concatenate((labels_val, dataset[participant]['labels_sessions']),axis=0)\n",
    "    X_val = X_val[1:,:]\n",
    "    Y_val = Y_val[1:]\n",
    "    labels_val = labels_val[1:]\n",
    "    dic_aux['n_trials_val'] = {'male':np.sum(Y_val == 'M'),'female':np.sum(Y_val == 'F')}\n",
    "    dic_aux['proportion_trials_val'] = {'male':np.sum(Y_val == 'M')/(np.sum(Y_val == 'M')+np.sum(Y_val == 'F')),\n",
    "                                      'female':np.sum(Y_val == 'F')/(np.sum(Y_val == 'M')+np.sum(Y_val == 'F'))}\n",
    "        \n",
    "    info_exp[f'it_{it}']=dic_aux\n",
    "    dic_aux={}\n",
    "\n",
    "    #--------------------------  CSP TRANSFORM -------------------------------#\n",
    "    csp = CSP(n_components = n_features, reg='oas', norm_trace = True)\n",
    "    csp.fit(X_train, labels_train)\n",
    "    X_train_CSP = csp.transform(X_train)\n",
    "    X_val_CSP = csp.transform(X_val)\n",
    "    X_test_CSP = csp.transform(X_test)\n",
    "\n",
    "    #-------------------------CLASSIFIER 1 -----------------------------#\n",
    "    acc_train = None\n",
    "    acc_val = None\n",
    "    acc_test = None\n",
    "    \n",
    "    tol = 1e-4\n",
    "    scaler = StandardScaler()\n",
    "    clf = LinearDiscriminantAnalysis(tol=tol)\n",
    "    \n",
    "    X_train_CSP_ = scaler.fit_transform(X_train_CSP, Y_train)\n",
    "    X_val_CSP_ = scaler.transform(X_val_CSP)\n",
    "    X_test_CSP_ = scaler.transform(X_test_CSP)\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train_CSP_, Y_train)\n",
    "    acc_train = clf.score(X_train_CSP_ , Y_train)\n",
    "    acc_val = clf.score(X_val_CSP_ , Y_val)\n",
    "    acc_test = clf.score(X_test_CSP_, Y_test)\n",
    "    \n",
    "    dic_aux['clf_1']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test}\n",
    "    \n",
    "    #-----------------------CLASSIFIER 2 -----------------------------#\n",
    "    acc_train = None\n",
    "    acc_val = None\n",
    "    acc_test = None\n",
    "    \n",
    "    tol = 1e-4\n",
    "    scaler = StandardScaler()\n",
    "    clf = svm.SVC(C=1.0, kernel='linear', tol=tol)\n",
    "    \n",
    "    X_train_CSP_ = scaler.fit_transform(X_train_CSP, Y_train)\n",
    "    X_val_CSP_ = scaler.transform(X_val_CSP)\n",
    "    X_test_CSP_ = scaler.transform(X_test_CSP)\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train_CSP_, Y_train)\n",
    "    acc_train = clf.score(X_train_CSP_ , Y_train)\n",
    "    acc_val = clf.score(X_val_CSP_ , Y_val)\n",
    "    acc_test = clf.score(X_test_CSP_, Y_test)\n",
    "    \n",
    "    dic_aux['clf_2']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test}\n",
    "    \n",
    "    #-----------------------CLASSIFIER 3 -----------------------------#\n",
    "    acc_train = None\n",
    "    acc_val = None\n",
    "    acc_test = None\n",
    "    \n",
    "    tol = 1e-4\n",
    "    scaler = StandardScaler()\n",
    "    clf = svm.SVC(C=1.0, kernel='rbf', tol=tol)\n",
    "    \n",
    "    X_train_CSP_ = scaler.fit_transform(X_train_CSP, Y_train)\n",
    "    X_val_CSP_ = scaler.transform(X_val_CSP)\n",
    "    X_test_CSP_ = scaler.transform(X_test_CSP)\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train_CSP_, Y_train)\n",
    "    acc_train = clf.score(X_train_CSP_ , Y_train)\n",
    "    acc_val = clf.score(X_val_CSP_ , Y_val)\n",
    "    acc_test = clf.score(X_test_CSP_, Y_test)\n",
    "    \n",
    "    dic_aux['clf_3']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test}\n",
    "    \n",
    "    \n",
    "    #-----------------------CLASSIFIER 4 -----------------------------#\n",
    "    acc_train_scores = []\n",
    "    acc_val_scores = []\n",
    "    acc_train = 0\n",
    "    acc_val = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    # Counter for patience\n",
    "    it_patience = 0\n",
    "    \n",
    "    # Best classifier in early stopping\n",
    "    best_clf = None\n",
    "    it_stop = 0 \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(10,8,5), activation='relu', solver='adam', alpha=0.0001,\n",
    "                        learning_rate='constant', learning_rate_init=0.01,max_iter=max_iter)\n",
    "    classes = np.unique(Y_train)\n",
    "\n",
    "    for it_ in range(max_iter):\n",
    "        # Scaler fit/transform\n",
    "        scaler.partial_fit(X_train_CSP, Y_train)\n",
    "        X_train_CSP_ = scaler.transform(X_train_CSP)\n",
    "        X_val_CSP_ = scaler.transform(X_val_CSP)\n",
    "        \n",
    "        # Classifier fit / evaluate\n",
    "        clf.partial_fit(X_train_CSP_,Y_train,classes=classes)\n",
    "        acc_train_scores.append(clf.score(X_train_CSP_,Y_train))\n",
    "        acc_val_scores.append(clf.score(X_val_CSP_,Y_val))\n",
    "        \n",
    "        if acc_val_scores[-1] >= acc_val:\n",
    "            acc_val = acc_val_scores[-1]\n",
    "            best_clf = deepcopy(clf)\n",
    "            it_stop = it_\n",
    "            it_patience = 0\n",
    "        else: \n",
    "            it_patience += 1\n",
    "        \n",
    "        if it_patience >= patience:\n",
    "            break\n",
    "        \n",
    "    X_test_CSP_ = scaler.transform(X_test_CSP)    \n",
    "    acc_test = best_clf.score(X_test_CSP_,Y_test)\n",
    "    acc_train = acc_train_scores[it_stop] \n",
    "     \n",
    "    dic_aux['clf_4']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test,\n",
    "                      'acc_train_scores': acc_train_scores, 'acc_val_scores': acc_val_scores, 'it_stop':it_stop}\n",
    "    \n",
    "    #-----------------------CLASSIFIER 5 -----------------------------#\n",
    "    acc_train_scores = []\n",
    "    acc_val_scores = []\n",
    "    acc_train = 0\n",
    "    acc_val = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    # Counter for patience\n",
    "    it_patience = 0\n",
    "    \n",
    "    # Best classifier in early stopping\n",
    "    best_clf = None\n",
    "    it_stop = 0 \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(10,8,3), activation='relu', solver='adam', alpha=0.0001,\n",
    "                        learning_rate='constant', learning_rate_init=0.01,max_iter=max_iter)\n",
    "    classes = np.unique(Y_train)\n",
    "\n",
    "    for it_ in range(max_iter):\n",
    "        # Scaler fit/transform\n",
    "        scaler.partial_fit(X_train_CSP, Y_train)\n",
    "        X_train_CSP_ = scaler.transform(X_train_CSP)\n",
    "        X_val_CSP_ = scaler.transform(X_val_CSP)\n",
    "        \n",
    "        # Classifier fit / evaluate\n",
    "        clf.partial_fit(X_train_CSP_,Y_train,classes=classes)\n",
    "        acc_train_scores.append(clf.score(X_train_CSP_,Y_train))\n",
    "        acc_val_scores.append(clf.score(X_val_CSP_,Y_val))\n",
    "        \n",
    "        if acc_val_scores[-1] >= acc_val:\n",
    "            acc_val = acc_val_scores[-1]\n",
    "            best_clf = deepcopy(clf)\n",
    "            it_stop = it_\n",
    "            it_patience = 0\n",
    "        else: \n",
    "            it_patience += 1\n",
    "        \n",
    "        if it_patience >= patience:\n",
    "            break\n",
    "        \n",
    "    X_test_CSP_ = scaler.transform(X_test_CSP)    \n",
    "    acc_test = best_clf.score(X_test_CSP_,Y_test)\n",
    "    acc_train = acc_train_scores[it_stop] \n",
    "     \n",
    "    dic_aux['clf_5']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test,\n",
    "                      'acc_train_scores': acc_train_scores, 'acc_val_scores': acc_val_scores, 'it_stop':it_stop}\n",
    "    \n",
    "    #-----------------------CLASSIFIER 6 -----------------------------#\n",
    "    acc_train_scores = []\n",
    "    acc_val_scores = []\n",
    "    acc_train = 0\n",
    "    acc_val = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    # Counter for patience\n",
    "    it_patience = 0\n",
    "    \n",
    "    # Best classifier in early stopping\n",
    "    best_clf = None\n",
    "    it_stop = 0 \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(10,4,2), activation='relu', solver='adam', alpha=0.0001,\n",
    "                        learning_rate='constant', learning_rate_init=0.01,max_iter=max_iter)\n",
    "    classes = np.unique(Y_train)\n",
    "\n",
    "    for it_ in range(max_iter):\n",
    "        # Scaler fit/transform\n",
    "        scaler.partial_fit(X_train_CSP, Y_train)\n",
    "        X_train_CSP_ = scaler.transform(X_train_CSP)\n",
    "        X_val_CSP_ = scaler.transform(X_val_CSP)\n",
    "        \n",
    "        # Classifier fit / evaluate\n",
    "        clf.partial_fit(X_train_CSP_,Y_train,classes=classes)\n",
    "        acc_train_scores.append(clf.score(X_train_CSP_,Y_train))\n",
    "        acc_val_scores.append(clf.score(X_val_CSP_,Y_val))\n",
    "        \n",
    "        if acc_val_scores[-1] >= acc_val:\n",
    "            acc_val = acc_val_scores[-1]\n",
    "            best_clf = deepcopy(clf)\n",
    "            it_stop = it_\n",
    "            it_patience = 0\n",
    "        else: \n",
    "            it_patience += 1\n",
    "        \n",
    "        if it_patience >= patience:\n",
    "            break\n",
    "        \n",
    "    X_test_CSP_ = scaler.transform(X_test_CSP)    \n",
    "    acc_test = best_clf.score(X_test_CSP_,Y_test)\n",
    "    acc_train = acc_train_scores[it_stop] \n",
    "     \n",
    "    dic_aux['clf_6']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test,\n",
    "                      'acc_train_scores': acc_train_scores, 'acc_val_scores': acc_val_scores, 'it_stop':it_stop}\n",
    "    \n",
    "    info_clfs[f'it_{it}']=dic_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos la tabla de los acc para cada iteraci√≥n y clasificador\n",
    "n_clfs = 6\n",
    "\n",
    "matrix_acc_train = np.zeros((n_clfs,N_it))\n",
    "matrix_acc_val = np.zeros((n_clfs,N_it))\n",
    "matrix_acc_test = np.zeros((n_clfs,N_it))\n",
    "\n",
    "for it0 in range(N_it):\n",
    "    for it1 in range(n_clfs):\n",
    "        matrix_acc_train[it1,it0] = info_clfs[f'it_{it0}'][f'clf_{it1+1}']['acc_train']\n",
    "        matrix_acc_val[it1,it0] = info_clfs[f'it_{it0}'][f'clf_{it1+1}']['acc_val']\n",
    "        matrix_acc_test[it1,it0] = info_clfs[f'it_{it0}'][f'clf_{it1+1}']['acc_test']\n",
    "\n",
    "acc_train_clfs_mean = matrix_acc_train.mean(axis=1,keepdims=True)\n",
    "acc_train_clfs_std = np.std(matrix_acc_train,axis=1,keepdims=True)\n",
    "\n",
    "acc_val_clfs_mean = matrix_acc_val.mean(axis=1,keepdims=True)\n",
    "acc_val_clfs_std = np.std(matrix_acc_val,axis=1,keepdims=True)\n",
    "\n",
    "acc_test_clfs_mean = matrix_acc_test.mean(axis=1,keepdims=True)\n",
    "acc_test_clfs_std = np.std(matrix_acc_test,axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.634677</td>\n",
       "      <td>0.727559</td>\n",
       "      <td>0.630703</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.705914</td>\n",
       "      <td>0.566278</td>\n",
       "      <td>0.441053</td>\n",
       "      <td>0.424987</td>\n",
       "      <td>0.514054</td>\n",
       "      <td>0.359125</td>\n",
       "      <td>0.479188</td>\n",
       "      <td>0.661299</td>\n",
       "      <td>0.344271</td>\n",
       "      <td>0.392439</td>\n",
       "      <td>0.488782</td>\n",
       "      <td>0.515894</td>\n",
       "      <td>0.459390</td>\n",
       "      <td>0.323711</td>\n",
       "      <td>0.609704</td>\n",
       "      <td>0.507920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.728084</td>\n",
       "      <td>0.646269</td>\n",
       "      <td>0.550663</td>\n",
       "      <td>0.704848</td>\n",
       "      <td>0.564157</td>\n",
       "      <td>0.462632</td>\n",
       "      <td>0.419237</td>\n",
       "      <td>0.518919</td>\n",
       "      <td>0.356990</td>\n",
       "      <td>0.527575</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.423323</td>\n",
       "      <td>0.506944</td>\n",
       "      <td>0.515373</td>\n",
       "      <td>0.472840</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0.624798</td>\n",
       "      <td>0.507392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_3</th>\n",
       "      <td>0.532874</td>\n",
       "      <td>0.613648</td>\n",
       "      <td>0.534622</td>\n",
       "      <td>0.469496</td>\n",
       "      <td>0.727224</td>\n",
       "      <td>0.430541</td>\n",
       "      <td>0.504737</td>\n",
       "      <td>0.429692</td>\n",
       "      <td>0.522703</td>\n",
       "      <td>0.504803</td>\n",
       "      <td>0.585848</td>\n",
       "      <td>0.601181</td>\n",
       "      <td>0.399479</td>\n",
       "      <td>0.322151</td>\n",
       "      <td>0.586004</td>\n",
       "      <td>0.587806</td>\n",
       "      <td>0.460424</td>\n",
       "      <td>0.423196</td>\n",
       "      <td>0.490027</td>\n",
       "      <td>0.484688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_4</th>\n",
       "      <td>0.550371</td>\n",
       "      <td>0.667717</td>\n",
       "      <td>0.590982</td>\n",
       "      <td>0.484881</td>\n",
       "      <td>0.633990</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.408421</td>\n",
       "      <td>0.499216</td>\n",
       "      <td>0.586486</td>\n",
       "      <td>0.481857</td>\n",
       "      <td>0.575442</td>\n",
       "      <td>0.621578</td>\n",
       "      <td>0.524479</td>\n",
       "      <td>0.381257</td>\n",
       "      <td>0.626068</td>\n",
       "      <td>0.478895</td>\n",
       "      <td>0.541645</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.415633</td>\n",
       "      <td>0.428194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_5</th>\n",
       "      <td>0.544539</td>\n",
       "      <td>0.653018</td>\n",
       "      <td>0.447665</td>\n",
       "      <td>0.518833</td>\n",
       "      <td>0.622802</td>\n",
       "      <td>0.464475</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>0.451124</td>\n",
       "      <td>0.544324</td>\n",
       "      <td>0.520811</td>\n",
       "      <td>0.518210</td>\n",
       "      <td>0.593666</td>\n",
       "      <td>0.403125</td>\n",
       "      <td>0.348243</td>\n",
       "      <td>0.570513</td>\n",
       "      <td>0.495571</td>\n",
       "      <td>0.523539</td>\n",
       "      <td>0.436598</td>\n",
       "      <td>0.534232</td>\n",
       "      <td>0.513728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_6</th>\n",
       "      <td>0.476140</td>\n",
       "      <td>0.642520</td>\n",
       "      <td>0.639828</td>\n",
       "      <td>0.485411</td>\n",
       "      <td>0.679275</td>\n",
       "      <td>0.461294</td>\n",
       "      <td>0.356842</td>\n",
       "      <td>0.462624</td>\n",
       "      <td>0.607027</td>\n",
       "      <td>0.465848</td>\n",
       "      <td>0.491155</td>\n",
       "      <td>0.546430</td>\n",
       "      <td>0.346354</td>\n",
       "      <td>0.513312</td>\n",
       "      <td>0.615919</td>\n",
       "      <td>0.589891</td>\n",
       "      <td>0.539058</td>\n",
       "      <td>0.495361</td>\n",
       "      <td>0.648518</td>\n",
       "      <td>0.496304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "clf_1  0.634677  0.727559  0.630703  0.551724  0.705914  0.566278  0.441053   \n",
       "clf_2  0.658537  0.728084  0.646269  0.550663  0.704848  0.564157  0.462632   \n",
       "clf_3  0.532874  0.613648  0.534622  0.469496  0.727224  0.430541  0.504737   \n",
       "clf_4  0.550371  0.667717  0.590982  0.484881  0.633990  0.402439  0.408421   \n",
       "clf_5  0.544539  0.653018  0.447665  0.518833  0.622802  0.464475  0.536842   \n",
       "clf_6  0.476140  0.642520  0.639828  0.485411  0.679275  0.461294  0.356842   \n",
       "\n",
       "             7         8         9         10        11        12        13  \\\n",
       "clf_1  0.424987  0.514054  0.359125  0.479188  0.661299  0.344271  0.392439   \n",
       "clf_2  0.419237  0.518919  0.356990  0.527575  0.695652  0.358333  0.423323   \n",
       "clf_3  0.429692  0.522703  0.504803  0.585848  0.601181  0.399479  0.322151   \n",
       "clf_4  0.499216  0.586486  0.481857  0.575442  0.621578  0.524479  0.381257   \n",
       "clf_5  0.451124  0.544324  0.520811  0.518210  0.593666  0.403125  0.348243   \n",
       "clf_6  0.462624  0.607027  0.465848  0.491155  0.546430  0.346354  0.513312   \n",
       "\n",
       "             14        15        16        17        18        19  \n",
       "clf_1  0.488782  0.515894  0.459390  0.323711  0.609704  0.507920  \n",
       "clf_2  0.506944  0.515373  0.472840  0.309278  0.624798  0.507392  \n",
       "clf_3  0.586004  0.587806  0.460424  0.423196  0.490027  0.484688  \n",
       "clf_4  0.626068  0.478895  0.541645  0.463918  0.415633  0.428194  \n",
       "clf_5  0.570513  0.495571  0.523539  0.436598  0.534232  0.513728  \n",
       "clf_6  0.615919  0.589891  0.539058  0.495361  0.648518  0.496304  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_train_df = pd.DataFrame(matrix_acc_train,index=['clf_1','clf_2','clf_3','clf_4','clf_5','clf_6'])\n",
    "accs_val_df = pd.DataFrame(matrix_acc_val,index=['clf_1','clf_2','clf_3','clf_4','clf_5','clf_6'])\n",
    "accs_test_df = pd.DataFrame(matrix_acc_test,index=['clf_1','clf_2','clf_3','clf_4','clf_5','clf_6'])\n",
    "accs_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_test_df.to_csv('acc_test_prueba_borrar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN MEAN</th>\n",
       "      <th>TRAIN STD</th>\n",
       "      <th>VAL MEAN</th>\n",
       "      <th>VAL STD</th>\n",
       "      <th>TEST MEAN</th>\n",
       "      <th>TEST STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.642191</td>\n",
       "      <td>0.037987</td>\n",
       "      <td>0.544589</td>\n",
       "      <td>0.127168</td>\n",
       "      <td>0.516933</td>\n",
       "      <td>0.115620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.647471</td>\n",
       "      <td>0.036462</td>\n",
       "      <td>0.544610</td>\n",
       "      <td>0.122844</td>\n",
       "      <td>0.527592</td>\n",
       "      <td>0.118050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_3</th>\n",
       "      <td>0.839688</td>\n",
       "      <td>0.019528</td>\n",
       "      <td>0.539080</td>\n",
       "      <td>0.102971</td>\n",
       "      <td>0.510557</td>\n",
       "      <td>0.088911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_4</th>\n",
       "      <td>0.771887</td>\n",
       "      <td>0.070144</td>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.106314</td>\n",
       "      <td>0.518174</td>\n",
       "      <td>0.084574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_5</th>\n",
       "      <td>0.766542</td>\n",
       "      <td>0.072283</td>\n",
       "      <td>0.606488</td>\n",
       "      <td>0.100791</td>\n",
       "      <td>0.512093</td>\n",
       "      <td>0.070887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_6</th>\n",
       "      <td>0.730410</td>\n",
       "      <td>0.083381</td>\n",
       "      <td>0.608424</td>\n",
       "      <td>0.096889</td>\n",
       "      <td>0.527956</td>\n",
       "      <td>0.090642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAIN MEAN  TRAIN STD  VAL MEAN   VAL STD  TEST MEAN  TEST STD\n",
       "clf_1    0.642191   0.037987  0.544589  0.127168   0.516933  0.115620\n",
       "clf_2    0.647471   0.036462  0.544610  0.122844   0.527592  0.118050\n",
       "clf_3    0.839688   0.019528  0.539080  0.102971   0.510557  0.088911\n",
       "clf_4    0.771887   0.070144  0.595092  0.106314   0.518174  0.084574\n",
       "clf_5    0.766542   0.072283  0.606488  0.100791   0.512093  0.070887\n",
       "clf_6    0.730410   0.083381  0.608424  0.096889   0.527956  0.090642"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(np.concatenate((acc_train_clfs_mean,acc_train_clfs_std,\n",
    "                                          acc_val_clfs_mean,acc_val_clfs_std,\n",
    "                                          acc_test_clfs_mean,acc_test_clfs_std),axis=1),\n",
    "                          columns = ['TRAIN MEAN', 'TRAIN STD','VAL MEAN', 'VAL STD','TEST MEAN', 'TEST STD']\n",
    "                          ,index=['clf_1','clf_2','clf_3','clf_4','clf_5','clf_6'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_1samp\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significancia: 0.0083\n",
      "Intervalo de confianza: 99.16666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.626922</td>\n",
       "      <td>3.945285e-08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.621445</td>\n",
       "      <td>5.567034e-08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_3</th>\n",
       "      <td>0.626331</td>\n",
       "      <td>4.095549e-08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_4</th>\n",
       "      <td>0.648494</td>\n",
       "      <td>9.680973e-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_5</th>\n",
       "      <td>0.636171</td>\n",
       "      <td>2.180989e-08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_6</th>\n",
       "      <td>0.635462</td>\n",
       "      <td>2.283578e-08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statistics       p-value     H0\n",
       "clf_1    0.626922  3.945285e-08  False\n",
       "clf_2    0.621445  5.567034e-08  False\n",
       "clf_3    0.626331  4.095549e-08  False\n",
       "clf_4    0.648494  9.680973e-09  False\n",
       "clf_5    0.636171  2.180989e-08  False\n",
       "clf_6    0.635462  2.283578e-08  False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "alpha_bonferroni = alpha / 6\n",
    "\n",
    "test_norm = pd.DataFrame(columns=['statistics','p-value','H0'])\n",
    "clf_names = accs_test_df.index.values.tolist()\n",
    "\n",
    "for clf in clf_names: \n",
    "    acc_test = accs_test_df.loc[clf]\n",
    "    norm_test = ks_1samp(acc_test,stats.norm.cdf)\n",
    "    if norm_test.pvalue <= alpha_bonferroni:\n",
    "        test_norm.loc[clf]=[norm_test.statistic,norm_test.pvalue,False]\n",
    "    else:\n",
    "        test_norm.loc[clf]=[norm_test.statistic,norm_test.pvalue,True]\n",
    "\n",
    "print(f'Significancia: {alpha_bonferroni:.2}')\n",
    "print(f'Intervalo de confianza: {100*(1-alpha_bonferroni)}')\n",
    "test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significancia: 0.0083\n",
      "Intervalo de confianza: 99.16666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.621513</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>0.311794</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_3</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.595819</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_4</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.388376</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_5</th>\n",
       "      <td>84.0</td>\n",
       "      <td>0.452375</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_6</th>\n",
       "      <td>77.0</td>\n",
       "      <td>0.311794</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statics   p-value    H0\n",
       "clf_1     91.0  0.621513  True\n",
       "clf_2     77.0  0.311794  True\n",
       "clf_3     90.0  0.595819  True\n",
       "clf_4     81.0  0.388376  True\n",
       "clf_5     84.0  0.452375  True\n",
       "clf_6     77.0  0.311794  True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = 0.5\n",
    "test = pd.DataFrame(columns=['statics','p-value','H0'])\n",
    "\n",
    "for clf in clf_names: \n",
    "    acc_test = accs_test_df.loc[clf]\n",
    "    w_test = wilcoxon(acc_test-mu)\n",
    "    if w_test.pvalue <= alpha_bonferroni:\n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,False]\n",
    "    else: \n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,True]\n",
    "\n",
    "print(f'Significancia: {alpha_bonferroni:.2}')\n",
    "print(f'Intervalo de confianza: {100*(1-alpha_bonferroni)}')\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('fairness1.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc5a03d0949048036a82bc8df2a1f9a734ae5fa45f6ea724030c79b47976db34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
