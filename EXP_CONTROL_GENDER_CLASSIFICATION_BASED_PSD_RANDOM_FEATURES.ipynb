{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GroupKFold, GridSearchCV  , StratifiedGroupKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "from random import sample, shuffle\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.base import clone\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_path_root = \"/home/bruno/Academico/Doctorado/Neuro_Fairness/Shu_Dataset/004_Dataset_6_Random_Feature_Extraction/\"\n",
    "dataset_path_root = \"/home/bzorzet/Academico/Neuro_Fairness/Shu_Dataset/002_Dataset_Traditional_Feature_Extraction/\"\n",
    "\n",
    "participants=[\"sub-001\",\"sub-002\",\"sub-003\",\"sub-004\",\"sub-005\",\n",
    "              \"sub-006\",\"sub-007\",\"sub-008\",\"sub-009\",\"sub-010\",\n",
    "              \"sub-011\",\"sub-012\",\"sub-013\",\"sub-014\",\"sub-015\",\n",
    "              \"sub-016\",\"sub-017\",\"sub-018\",\"sub-019\",\"sub-020\",\n",
    "              \"sub-021\",\"sub-022\",\"sub-023\",\"sub-024\",\"sub-025\"]\n",
    "sessions = [\"ses-01\",\"ses-02\",\"ses-03\",\"ses-04\",\"ses-05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset={}\n",
    "for participant in participants:\n",
    "    dataset[participant]={}\n",
    "    data_path=participant+\"_task_motorimagery_eeg_preprocessing_trad_feature.mat\"\n",
    "    data=sio.loadmat(dataset_path_root + data_path)\n",
    "    for session in sessions:\n",
    "        dataset[participant][session +'_data_band_power']=data[session +'_data_band_power']\n",
    "        dataset[participant][session +'_labels_trials']=data[session +'_labels_trials']\n",
    "    dataset[participant]['sfreq']=np.squeeze(data['sfreq'])\n",
    "    dataset[participant]['age']=np.squeeze(data['age'])\n",
    "    dataset[participant]['gender']=data['gender'][0]\n",
    "    dataset[participant]['group_medidator']=data['group_medidator'][0]\n",
    "    dataset[participant]['id_participant']=data['id_participant'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participantes hombres: ['sub-001', 'sub-002', 'sub-008', 'sub-012', 'sub-013', 'sub-015', 'sub-017', 'sub-018', 'sub-019', 'sub-021', 'sub-022', 'sub-023', 'sub-025']\n",
      "Participantes mujeres: ['sub-003', 'sub-004', 'sub-005', 'sub-006', 'sub-007', 'sub-009', 'sub-010', 'sub-011', 'sub-014', 'sub-016', 'sub-020', 'sub-024']\n"
     ]
    }
   ],
   "source": [
    "index_female = []\n",
    "index_male = []\n",
    "for participant in participants:\n",
    "    if dataset[participant]['gender'] == 'M':\n",
    "        index_male.append(participant)\n",
    "    elif dataset[participant]['gender'] == 'F':\n",
    "        index_female.append(participant)\n",
    "print(f\"Participantes hombres: {index_male}\")\n",
    "print(f\"Participantes mujeres: {index_female}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in participants:\n",
    "    data_ = np.concatenate((dataset[participant]['ses-01_data_band_power'],\n",
    "                            dataset[participant]['ses-02_data_band_power'],\n",
    "                            dataset[participant]['ses-03_data_band_power'],\n",
    "                            dataset[participant]['ses-04_data_band_power'],\n",
    "                            dataset[participant]['ses-05_data_band_power']),axis=0)\n",
    "    \n",
    "    dataset[participant]['data_band_power'] = data_\n",
    "    dataset[participant]['data_gender'] =  np.array(list(dataset[participant]['gender']) * data_.shape[0])\n",
    "    dataset[participant]['group_participant'] =  np.array(list([participant]) * data_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 6 #RANDOM SAMPLE QUANTITY\n",
    "N_sr = 100 #RANDOM SAMPLING QUANTITY\n",
    "\n",
    "N_folds = 20\n",
    "n_test_participant = 2\n",
    "n_val_participant = 2 \n",
    "n_ign_participant = 1\n",
    "max_iter = 200\n",
    "patience = 50 \n",
    "\n",
    "info_exp = {}\n",
    "for it_sr in range(N_sr):\n",
    "    info_folds = {}\n",
    "    info_clfs = {}\n",
    "\n",
    "    #Random sample per subject\n",
    "    for participant in participants:\n",
    "        X = dataset[participant]['data_band_power']\n",
    "        n_0 = X.shape[0]\n",
    "        n_1 = X.shape[1]\n",
    "        n_2 = X.shape[2]\n",
    "        X =X.reshape((n_0,n_1*n_2))\n",
    "        X_random = np.zeros((n_0,n_features))\n",
    "        for it0 in range(n_0):\n",
    "            X_random[it0,:]=sample(X[it0,:].tolist(), n_features)\n",
    "        dataset[participant]['data_random'] = np.array(X_random)\n",
    "\n",
    "    #Train Model    \n",
    "    for it in range(N_folds):\n",
    "        dic_aux = {}\n",
    "        \n",
    "        X_train = None\n",
    "        X_val = None\n",
    "        X_test = None \n",
    "        \n",
    "        X_train_ = None\n",
    "        X_val_ = None\n",
    "        X_test_ = None\n",
    "        \n",
    "        idx_male = index_male.copy()\n",
    "        idx_female = index_female.copy()\n",
    "        \n",
    "        # TEST PARTICIPANTS:\n",
    "        idx_male_test = sample(idx_male, n_test_participant)\n",
    "        idx_female_test = sample(idx_female, n_test_participant)\n",
    "        for it_ in range(n_test_participant):\n",
    "            idx_male.remove(idx_male_test[it_])\n",
    "            idx_female.remove(idx_female_test[it_])\n",
    "        idx_test = idx_male_test + idx_female_test\n",
    "        dic_aux['reg_idx_test'] = idx_test   \n",
    "        \n",
    "        # VALIDATION PARTICIPANTS:\n",
    "        idx_male_val = sample(idx_male, n_val_participant)\n",
    "        idx_female_val = sample(idx_female, n_val_participant)\n",
    "        for it_ in range(n_val_participant):\n",
    "            idx_male.remove(idx_male_val[it_])\n",
    "            idx_female.remove(idx_female_val[it_])\n",
    "        idx_val = idx_male_val + idx_female_val\n",
    "        dic_aux['reg_idx_val'] = idx_val  \n",
    "        \n",
    "        # TRAIN PARTICIPANTS:\n",
    "        idx_male_ignore = sample(idx_male, n_ign_participant)\n",
    "        for it_ in range(n_ign_participant):\n",
    "            idx_male.remove(idx_male_ignore[it_])\n",
    "        idx_male_train = idx_male.copy()\n",
    "        idx_female_train = idx_female.copy()\n",
    "        idx_train = idx_male_train + idx_female_train\n",
    "        dic_aux['reg_idx_train'] = idx_train    \n",
    "            \n",
    "        \n",
    "        # CONCATENAMOS EL CONJUNTO DE DATOS\n",
    "        # TEST\n",
    "        X_test = np.zeros((1,n_features))\n",
    "        Y_test = np.zeros(1)\n",
    "        for participant in idx_test:\n",
    "            X_test = np.concatenate((X_test, dataset[participant]['data_random']),axis=0)\n",
    "            Y_test = np.concatenate((Y_test, dataset[participant]['data_gender']),axis=0)\n",
    "        X_test = X_test[1:,:]\n",
    "        Y_test = Y_test[1:]\n",
    "        dic_aux['n_trials_test'] = {'male':np.sum(Y_test == 'M'),'female':np.sum(Y_test == 'F')}\n",
    "        dic_aux['proportion_trials_test'] = {'male':np.sum(Y_test == 'M')/(np.sum(Y_test == 'M')+np.sum(Y_test == 'F')),\n",
    "                                        'female':np.sum(Y_test == 'F')/(np.sum(Y_test == 'M')+np.sum(Y_test == 'F'))}\n",
    "        # VALIDATION\n",
    "        X_val = np.zeros((1,n_features))\n",
    "        Y_val = np.zeros(1)\n",
    "        for participant in idx_val:\n",
    "            X_val = np.concatenate((X_val, dataset[participant]['data_random']),axis=0)\n",
    "            Y_val = np.concatenate((Y_val, dataset[participant]['data_gender']),axis=0)\n",
    "        X_val = X_val[1:,:]\n",
    "        Y_val = Y_val[1:]\n",
    "        dic_aux['n_trials_val'] = {'male':np.sum(Y_val == 'M'),'female':np.sum(Y_val == 'F')}\n",
    "        dic_aux['proportion_trials_val'] = {'male':np.sum(Y_val == 'M')/(np.sum(Y_val == 'M')+np.sum(Y_val == 'F')),\n",
    "                                        'female':np.sum(Y_val == 'F')/(np.sum(Y_val == 'M')+np.sum(Y_val == 'F'))}\n",
    "            \n",
    "        # TRAIN\n",
    "        X_train = np.zeros((1,n_features))\n",
    "        Y_train = np.zeros(1)\n",
    "        for participant in idx_train:\n",
    "            X_train = np.concatenate((X_train, dataset[participant]['data_random']),axis=0)\n",
    "            Y_train = np.concatenate((Y_train, dataset[participant]['data_gender']),axis=0)\n",
    "        X_train = X_train[1:,:]\n",
    "        Y_train = Y_train[1:]\n",
    "        dic_aux['n_trials_train'] = {'male':np.sum(Y_train == 'M'),'female':np.sum(Y_train == 'F')}\n",
    "        dic_aux['proportion_trials_train'] = {'male':np.sum(Y_train == 'M')/(np.sum(Y_train == 'M')+np.sum(Y_train == 'F')),\n",
    "                                        'female':np.sum(Y_train == 'F')/(np.sum(Y_train == 'M')+np.sum(Y_train == 'F'))}   \n",
    "        \n",
    "        info_folds[f'fold_{it}']=dic_aux\n",
    "\n",
    "        \n",
    "        dic_aux={}\n",
    "         #-----------------------CLASSIFIER 1 -----------------------------#\n",
    "        acc_train = None\n",
    "        acc_val = None\n",
    "        acc_test = None\n",
    "        \n",
    "        tol = 1e-4\n",
    "        scaler = StandardScaler()\n",
    "        clf = LinearDiscriminantAnalysis(tol=tol)\n",
    "        \n",
    "        X_train_ = scaler.fit_transform(X_train, Y_train)\n",
    "        X_val_ = scaler.transform(X_val)\n",
    "        X_test_ = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        clf.fit(X_train_, Y_train)\n",
    "        acc_train = clf.score(X_train_ , Y_train)\n",
    "        acc_val = clf.score(X_val_ , Y_val)\n",
    "        acc_test = clf.score(X_test_, Y_test)\n",
    "        \n",
    "        dic_aux['clf_1']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test}\n",
    "\n",
    "\n",
    "\n",
    "        # #-----------------------CLASSIFIER 2 -----------------------------#\n",
    "        # acc_train = None\n",
    "        # acc_val = None\n",
    "        # acc_test = None\n",
    "        \n",
    "        # tol = 1e-4\n",
    "        # scaler = StandardScaler()\n",
    "        # clf = svm.SVC(C=1.0, kernel='linear', tol=tol)\n",
    "        \n",
    "        # X_train_ = scaler.fit_transform(X_train, Y_train)\n",
    "        # X_val_ = scaler.transform(X_val)\n",
    "        # X_test_ = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        # clf.fit(X_train_, Y_train)\n",
    "        # acc_train = clf.score(X_train_ , Y_train)\n",
    "        # acc_val = clf.score(X_val_ , Y_val)\n",
    "        # acc_test = clf.score(X_test_, Y_test)\n",
    "        \n",
    "        # dic_aux['clf_2']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test}\n",
    "        \n",
    "        # #-----------------------CLASSIFIER 3 -----------------------------#\n",
    "        # acc_train = None\n",
    "        # acc_val = None\n",
    "        # acc_test = None\n",
    "        \n",
    "        # tol = 1e-4\n",
    "        # scaler = StandardScaler()\n",
    "        # clf = svm.SVC(C=1.0, kernel='rbf', tol=tol)\n",
    "        \n",
    "        # X_train_ = scaler.fit_transform(X_train, Y_train)\n",
    "        # X_val_ = scaler.transform(X_val)\n",
    "        # X_test_ = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        # clf.fit(X_train_, Y_train)\n",
    "        # acc_train = clf.score(X_train_ , Y_train)\n",
    "        # acc_val = clf.score(X_val_ , Y_val)\n",
    "        # acc_test = clf.score(X_test_, Y_test)\n",
    "        \n",
    "        # dic_aux['clf_3']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test}\n",
    "        \n",
    "        \n",
    "        # #-----------------------CLASSIFIER 4 -----------------------------#\n",
    "        # acc_train_scores = []\n",
    "        # acc_val_scores = []\n",
    "        # acc_train = 0\n",
    "        # acc_val = 0\n",
    "        # acc_test = 0\n",
    "        \n",
    "        # # Counter for patience\n",
    "        # it_patience = 0\n",
    "        \n",
    "        # # Best classifier in early stopping\n",
    "        # best_clf = None\n",
    "        # it_stop = 0 \n",
    "        \n",
    "        # scaler = StandardScaler()\n",
    "        # clf = MLPClassifier(hidden_layer_sizes=(10,8,5), activation='relu', solver='adam', alpha=0.0001,\n",
    "        #                     learning_rate='constant', learning_rate_init=0.01,max_iter=max_iter)\n",
    "        # classes = np.unique(Y_train)\n",
    "\n",
    "        # for it_ in range(max_iter):\n",
    "        #     # Scaler fit/transform\n",
    "        #     scaler.partial_fit(X_train, Y_train)\n",
    "        #     X_train_ = scaler.transform(X_train)\n",
    "        #     X_val_ = scaler.transform(X_val)\n",
    "            \n",
    "        #     # Classifier fit / evaluate\n",
    "        #     clf.partial_fit(X_train_,Y_train,classes=classes)\n",
    "        #     acc_train_scores.append(clf.score(X_train_,Y_train))\n",
    "        #     acc_val_scores.append(clf.score(X_val_,Y_val))\n",
    "            \n",
    "        #     if acc_val_scores[-1] >= acc_val:\n",
    "        #         acc_val = acc_val_scores[-1]\n",
    "        #         best_clf = deepcopy(clf)\n",
    "        #         it_stop = it_\n",
    "        #         it_patience = 0\n",
    "        #     else: \n",
    "        #         it_patience += 1\n",
    "            \n",
    "        #     if it_patience >= patience:\n",
    "        #         break\n",
    "            \n",
    "        # X_test_ = scaler.transform(X_test)    \n",
    "        # acc_test = best_clf.score(X_test_,Y_test)\n",
    "        # acc_train = acc_train_scores[it_stop] \n",
    "        \n",
    "        # dic_aux['clf_4']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test,\n",
    "        #                 'acc_train_scores': acc_train_scores, 'acc_val_scores': acc_val_scores, 'it_stop':it_stop}\n",
    "        \n",
    "        # #-----------------------CLASSIFIER 5 -----------------------------#\n",
    "        # acc_train_scores = []\n",
    "        # acc_val_scores = []\n",
    "        # acc_train = 0\n",
    "        # acc_val = 0\n",
    "        # acc_test = 0\n",
    "        \n",
    "        # # Counter for patience\n",
    "        # it_patience = 0\n",
    "        \n",
    "        # # Best classifier in early stopping\n",
    "        # best_clf = None\n",
    "        # it_stop = 0 \n",
    "        \n",
    "        # scaler = StandardScaler()\n",
    "        # clf = MLPClassifier(hidden_layer_sizes=(10,8,3), activation='relu', solver='adam', alpha=0.0001,\n",
    "        #                     learning_rate='constant', learning_rate_init=0.01,max_iter=max_iter)\n",
    "        # classes = np.unique(Y_train)\n",
    "\n",
    "        # for it_ in range(max_iter):\n",
    "        #     # Scaler fit/transform\n",
    "        #     scaler.partial_fit(X_train, Y_train)\n",
    "        #     X_train_ = scaler.transform(X_train)\n",
    "        #     X_val_ = scaler.transform(X_val)\n",
    "            \n",
    "        #     # Classifier fit / evaluate\n",
    "        #     clf.partial_fit(X_train_,Y_train,classes=classes)\n",
    "        #     acc_train_scores.append(clf.score(X_train_,Y_train))\n",
    "        #     acc_val_scores.append(clf.score(X_val_,Y_val))\n",
    "            \n",
    "        #     if acc_val_scores[-1] >= acc_val:\n",
    "        #         acc_val = acc_val_scores[-1]\n",
    "        #         best_clf = deepcopy(clf)\n",
    "        #         it_stop = it_\n",
    "        #         it_patience = 0\n",
    "        #     else: \n",
    "        #         it_patience += 1\n",
    "            \n",
    "        #     if it_patience >= patience:\n",
    "        #         break\n",
    "            \n",
    "        # X_test_ = scaler.transform(X_test)    \n",
    "        # acc_test = best_clf.score(X_test_,Y_test)\n",
    "        # acc_train = acc_train_scores[it_stop] \n",
    "        \n",
    "        # dic_aux['clf_5']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test,\n",
    "        #                 'acc_train_scores': acc_train_scores, 'acc_val_scores': acc_val_scores, 'it_stop':it_stop}\n",
    "        \n",
    "        # #-----------------------CLASSIFIER 6 -----------------------------#\n",
    "        # acc_train_scores = []\n",
    "        # acc_val_scores = []\n",
    "        # acc_train = 0\n",
    "        # acc_val = 0\n",
    "        # acc_test = 0\n",
    "        \n",
    "        # # Counter for patience\n",
    "        # it_patience = 0\n",
    "        \n",
    "        # # Best classifier in early stopping\n",
    "        # best_clf = None\n",
    "        # it_stop = 0 \n",
    "        \n",
    "        # scaler = StandardScaler()\n",
    "        # clf = MLPClassifier(hidden_layer_sizes=(10,4,2), activation='relu', solver='adam', alpha=0.0001,\n",
    "        #                     learning_rate='constant', learning_rate_init=0.01,max_iter=max_iter)\n",
    "        # classes = np.unique(Y_train)\n",
    "\n",
    "        # for it_ in range(max_iter):\n",
    "        #     # Scaler fit/transform\n",
    "        #     scaler.partial_fit(X_train, Y_train)\n",
    "        #     X_train_ = scaler.transform(X_train)\n",
    "        #     X_val_ = scaler.transform(X_val)\n",
    "            \n",
    "        #     # Classifier fit / evaluate\n",
    "        #     clf.partial_fit(X_train_,Y_train,classes=classes)\n",
    "        #     acc_train_scores.append(clf.score(X_train_,Y_train))\n",
    "        #     acc_val_scores.append(clf.score(X_val_,Y_val))\n",
    "            \n",
    "        #     if acc_val_scores[-1] >= acc_val:\n",
    "        #         acc_val = acc_val_scores[-1]\n",
    "        #         best_clf = deepcopy(clf)\n",
    "        #         it_stop = it_\n",
    "        #         it_patience = 0\n",
    "        #     else: \n",
    "        #         it_patience += 1\n",
    "            \n",
    "        #     if it_patience >= patience:\n",
    "        #         break\n",
    "            \n",
    "        # X_test_ = scaler.transform(X_test)    \n",
    "        # acc_test = best_clf.score(X_test_,Y_test)\n",
    "        # acc_train = acc_train_scores[it_stop] \n",
    "        \n",
    "        # dic_aux['clf_6']={'estimator': clf, 'acc_train': acc_train, 'acc_val' : acc_val, 'acc_test' : acc_test,\n",
    "        #                 'acc_train_scores': acc_train_scores, 'acc_val_scores': acc_val_scores, 'it_stop':it_stop}\n",
    "        \n",
    "        info_clfs[f'fold_{it}']=dic_aux\n",
    "    info_exp[f'exp_{it_sr}'] = {'info_clfs':info_clfs, 'info_folds': info_folds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos la tabla de los acc para cada iteración y clasificador\n",
    "# Generamos las tablas en el siguiente formato: EXPERIMENTOS x FOLDS x CLFs\n",
    "N_clfs = 2\n",
    "\n",
    "\n",
    "matrix_acc_train = np.zeros((N_sr,N_folds,N_clfs))\n",
    "matrix_acc_val = np.zeros((N_sr,N_folds,N_clfs))\n",
    "matrix_acc_test = np.zeros((N_sr,N_folds,N_clfs))\n",
    "\n",
    "for it0 in range(N_sr):\n",
    "    for it1 in range(N_folds):\n",
    "        for it2 in range(N_clfs):\n",
    "            matrix_acc_train[it0,it1,it2] = info_exp[f'exp_{it0}']['info_clfs'][f'fold_{it1}'][f'clf_{it2+1}']['acc_train']\n",
    "            matrix_acc_val[it0,it1,it2] = info_exp[f'exp_{it0}']['info_clfs'][f'fold_{it1}'][f'clf_{it2+1}']['acc_val']\n",
    "            matrix_acc_test[it0,it1,it2] = info_exp[f'exp_{it0}']['info_clfs'][f'fold_{it1}'][f'clf_{it2+1}']['acc_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos los datos de la corrida\n",
    "\n",
    "save_path = \"control_experiment_result.mat\"\n",
    "data_save = {}\n",
    "data_save['matrix_acc_train'] = matrix_acc_train\n",
    "data_save['matrix_acc_val'] = matrix_acc_val\n",
    "data_save['matrix_acc_test'] = matrix_acc_test\n",
    "sio.savemat(save_path, data_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducimos la dimensión de 100x20x2 a 20x2\n",
    "acc_train_mean_exps = matrix_acc_train.mean(axis=0)\n",
    "acc_train_std_exps = np.std(matrix_acc_train,axis=0)\n",
    "\n",
    "acc_val_mean_exps = matrix_acc_val.mean(axis=0)\n",
    "acc_val_std_exps = np.std(matrix_acc_val,axis=0)\n",
    "\n",
    "acc_test_mean_exps = matrix_acc_test.mean(axis=0)\n",
    "acc_test_std_exps = np.std(matrix_acc_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducimos la dimensión de 100x20x2 a 2000x2\n",
    "acc_train_exps = matrix_acc_train.reshape((2000,2))\n",
    "\n",
    "acc_val_exps = matrix_acc_val.reshape((2000,2))\n",
    "\n",
    "acc_test_exps = matrix_acc_test.reshape((2000,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_total(X):\n",
    "    # X nxr n is exps r is folds\n",
    "    var_per_group = np.var(X,axis=0)\n",
    "    mean_per_group = X.mean(axis=0)\n",
    "\n",
    "    var_2 = np.var(mean_per_group)\n",
    "    var_1 = var_per_group.mean()\n",
    "    return var_1 + var_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_mean_clfs = acc_train_mean_exps.mean(axis=0,keepdims=True)\n",
    "acc_train_std_clfs = np.expand_dims(np.array([np.sqrt(variance_total(matrix_acc_train[:,:,0])),\n",
    "                        np.sqrt(variance_total(matrix_acc_train[:,:,1]))]),axis=0)\n",
    "\n",
    "acc_val_mean_clfs = acc_val_mean_exps.mean(axis=0,keepdims=True)\n",
    "acc_val_std_clfs = np.expand_dims(np.array([np.sqrt(variance_total(matrix_acc_val[:,:,0])),\n",
    "                        np.sqrt(variance_total(matrix_acc_val[:,:,1]))]),axis=0)\n",
    "\n",
    "acc_test_mean_clfs = acc_test_mean_exps.mean(axis=0,keepdims=True)\n",
    "acc_test_std_clfs = np.expand_dims(np.array([np.sqrt(variance_total(matrix_acc_test[:,:,0])),\n",
    "                        np.sqrt(variance_total(matrix_acc_test[:,:,1]))]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN MEAN</th>\n",
       "      <th>TRAIN STD</th>\n",
       "      <th>VAL MEAN</th>\n",
       "      <th>VAL STD</th>\n",
       "      <th>TEST MEAN</th>\n",
       "      <th>TEST STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.529762</td>\n",
       "      <td>0.018271</td>\n",
       "      <td>0.515691</td>\n",
       "      <td>0.056395</td>\n",
       "      <td>0.517148</td>\n",
       "      <td>0.055479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.505087</td>\n",
       "      <td>0.032208</td>\n",
       "      <td>0.505506</td>\n",
       "      <td>0.031088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAIN MEAN  TRAIN STD  VAL MEAN   VAL STD  TEST MEAN  TEST STD\n",
       "clf_1    0.529762   0.018271  0.515691  0.056395   0.517148  0.055479\n",
       "clf_2    0.521277   0.015154  0.505087  0.032208   0.505506  0.031088"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(np.concatenate((acc_train_mean_clfs.T,acc_train_std_clfs.T,\n",
    "                                          acc_val_mean_clfs.T,acc_val_std_clfs.T,\n",
    "                                          acc_test_mean_clfs.T,acc_test_std_clfs.T),axis=1),\n",
    "                          columns = ['TRAIN MEAN', 'TRAIN STD','VAL MEAN', 'VAL STD','TEST MEAN', 'TEST STD']\n",
    "                          ,index=['clf_1','clf_2'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.519474</td>\n",
       "      <td>0.575837</td>\n",
       "      <td>0.537978</td>\n",
       "      <td>0.453679</td>\n",
       "      <td>0.548221</td>\n",
       "      <td>0.544879</td>\n",
       "      <td>0.642707</td>\n",
       "      <td>0.442724</td>\n",
       "      <td>0.502848</td>\n",
       "      <td>0.604591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562404</td>\n",
       "      <td>0.494186</td>\n",
       "      <td>0.535029</td>\n",
       "      <td>0.547570</td>\n",
       "      <td>0.429931</td>\n",
       "      <td>0.492506</td>\n",
       "      <td>0.555615</td>\n",
       "      <td>0.527136</td>\n",
       "      <td>0.431485</td>\n",
       "      <td>0.534896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.528947</td>\n",
       "      <td>0.527720</td>\n",
       "      <td>0.541645</td>\n",
       "      <td>0.486501</td>\n",
       "      <td>0.511604</td>\n",
       "      <td>0.555966</td>\n",
       "      <td>0.540399</td>\n",
       "      <td>0.440144</td>\n",
       "      <td>0.493527</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547509</td>\n",
       "      <td>0.485201</td>\n",
       "      <td>0.556305</td>\n",
       "      <td>0.539297</td>\n",
       "      <td>0.484400</td>\n",
       "      <td>0.512145</td>\n",
       "      <td>0.524599</td>\n",
       "      <td>0.495970</td>\n",
       "      <td>0.501569</td>\n",
       "      <td>0.521044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "clf_1  0.519474  0.575837  0.537978  0.453679  0.548221  0.544879  0.642707   \n",
       "clf_2  0.528947  0.527720  0.541645  0.486501  0.511604  0.555966  0.540399   \n",
       "\n",
       "           7         8         9     ...      1990      1991      1992  \\\n",
       "clf_1  0.442724  0.502848  0.604591  ...  0.562404  0.494186  0.535029   \n",
       "clf_2  0.440144  0.493527  0.535211  ...  0.547509  0.485201  0.556305   \n",
       "\n",
       "           1993      1994      1995      1996      1997      1998      1999  \n",
       "clf_1  0.547570  0.429931  0.492506  0.555615  0.527136  0.431485  0.534896  \n",
       "clf_2  0.539297  0.484400  0.512145  0.524599  0.495970  0.501569  0.521044  \n",
       "\n",
       "[2 rows x 2000 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_train_df = pd.DataFrame(acc_train_exps.T,index=['clf_1','clf_2'])\n",
    "accs_val_df = pd.DataFrame(acc_val_exps.T,index=['clf_1','clf_2'])\n",
    "accs_test_df = pd.DataFrame(acc_test_exps.T,index=['clf_1','clf_2'])\n",
    "accs_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.513978</td>\n",
       "      <td>0.513167</td>\n",
       "      <td>0.514454</td>\n",
       "      <td>0.509933</td>\n",
       "      <td>0.520072</td>\n",
       "      <td>0.506473</td>\n",
       "      <td>0.522089</td>\n",
       "      <td>0.513918</td>\n",
       "      <td>0.524312</td>\n",
       "      <td>0.531335</td>\n",
       "      <td>0.516249</td>\n",
       "      <td>0.518624</td>\n",
       "      <td>0.522903</td>\n",
       "      <td>0.519472</td>\n",
       "      <td>0.510833</td>\n",
       "      <td>0.516573</td>\n",
       "      <td>0.526778</td>\n",
       "      <td>0.521595</td>\n",
       "      <td>0.502824</td>\n",
       "      <td>0.517369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.504596</td>\n",
       "      <td>0.502711</td>\n",
       "      <td>0.505102</td>\n",
       "      <td>0.502664</td>\n",
       "      <td>0.509087</td>\n",
       "      <td>0.501406</td>\n",
       "      <td>0.507873</td>\n",
       "      <td>0.504460</td>\n",
       "      <td>0.508137</td>\n",
       "      <td>0.511949</td>\n",
       "      <td>0.506115</td>\n",
       "      <td>0.507336</td>\n",
       "      <td>0.507103</td>\n",
       "      <td>0.502463</td>\n",
       "      <td>0.503723</td>\n",
       "      <td>0.505749</td>\n",
       "      <td>0.508425</td>\n",
       "      <td>0.506222</td>\n",
       "      <td>0.498329</td>\n",
       "      <td>0.506676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "clf_1  0.513978  0.513167  0.514454  0.509933  0.520072  0.506473  0.522089   \n",
       "clf_2  0.504596  0.502711  0.505102  0.502664  0.509087  0.501406  0.507873   \n",
       "\n",
       "             7         8         9         10        11        12        13  \\\n",
       "clf_1  0.513918  0.524312  0.531335  0.516249  0.518624  0.522903  0.519472   \n",
       "clf_2  0.504460  0.508137  0.511949  0.506115  0.507336  0.507103  0.502463   \n",
       "\n",
       "             14        15        16        17        18        19  \n",
       "clf_1  0.510833  0.516573  0.526778  0.521595  0.502824  0.517369  \n",
       "clf_2  0.503723  0.505749  0.508425  0.506222  0.498329  0.506676  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_train_means_df = pd.DataFrame(acc_train_mean_exps.T,index=['clf_1','clf_2'])\n",
    "accs_val_means_df = pd.DataFrame(acc_val_mean_exps.T,index=['clf_1','clf_2'])\n",
    "accs_test_means_df = pd.DataFrame(acc_test_mean_exps.T,index=['clf_1','clf_2'])\n",
    "accs_test_means_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_1samp\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significancia: 0.025\n",
      "Intervalo de confianza: 97.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.692456</td>\n",
       "      <td>4.252646e-10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>0.690874</td>\n",
       "      <td>4.790560e-10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statistics       p-value     H0\n",
       "clf_1    0.692456  4.252646e-10  False\n",
       "clf_2    0.690874  4.790560e-10  False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "alpha_bonferroni = alpha / 2\n",
    "\n",
    "test_norm = pd.DataFrame(columns=['statistics','p-value','H0'])\n",
    "clf_names = accs_test_means_df.index.values.tolist()\n",
    "\n",
    "for clf in clf_names: \n",
    "    acc_test = accs_test_means_df.loc[clf]\n",
    "    norm_test = ks_1samp(acc_test,stats.norm.cdf)\n",
    "    if norm_test.pvalue <= alpha_bonferroni:\n",
    "        test_norm.loc[clf]=[norm_test.statistic,norm_test.pvalue,False]\n",
    "    else:\n",
    "        test_norm.loc[clf]=[norm_test.statistic,norm_test.pvalue,True]\n",
    "\n",
    "print(f'Significancia: {alpha_bonferroni:.2}')\n",
    "print(f'Intervalo de confianza: {100*(1-alpha_bonferroni)}')\n",
    "test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.013978\n",
      "1     0.013167\n",
      "2     0.014454\n",
      "3     0.009933\n",
      "4     0.020072\n",
      "5     0.006473\n",
      "6     0.022089\n",
      "7     0.013918\n",
      "8     0.024312\n",
      "9     0.031335\n",
      "10    0.016249\n",
      "11    0.018624\n",
      "12    0.022903\n",
      "13    0.019472\n",
      "14    0.010833\n",
      "15    0.016573\n",
      "16    0.026778\n",
      "17    0.021595\n",
      "18    0.002824\n",
      "19    0.017369\n",
      "Name: clf_1, dtype: float64\n",
      "0     0.004596\n",
      "1     0.002711\n",
      "2     0.005102\n",
      "3     0.002664\n",
      "4     0.009087\n",
      "5     0.001406\n",
      "6     0.007873\n",
      "7     0.004460\n",
      "8     0.008137\n",
      "9     0.011949\n",
      "10    0.006115\n",
      "11    0.007336\n",
      "12    0.007103\n",
      "13    0.002463\n",
      "14    0.003723\n",
      "15    0.005749\n",
      "16    0.008425\n",
      "17    0.006222\n",
      "18   -0.001671\n",
      "19    0.006676\n",
      "Name: clf_2, dtype: float64\n",
      "Significancia: 0.025\n",
      "Intervalo de confianza: 97.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statics   p-value     H0\n",
       "clf_1      0.0  0.000089  False\n",
       "clf_2      2.0  0.000120  False"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = 0.5\n",
    "test = pd.DataFrame(columns=['statics','p-value','H0'])\n",
    "\n",
    "for clf in clf_names: \n",
    "    acc_test = accs_test_means_df.loc[clf]\n",
    "    w_test = wilcoxon(acc_test-mu,zero_method=\"zsplit\",method='approx')\n",
    "    if w_test.pvalue <= alpha_bonferroni:\n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,False]\n",
    "    else: \n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,True]\n",
    "\n",
    "print(f'Significancia: {alpha_bonferroni:.2}')\n",
    "print(f'Intervalo de confianza: {100*(1-alpha_bonferroni)}')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 1., 4., 3., 3., 3., 4., 0., 1.]),\n",
       " array([-0.00167087, -0.00030883,  0.0010532 ,  0.00241524,  0.00377728,\n",
       "         0.00513931,  0.00650135,  0.00786339,  0.00922542,  0.01058746,\n",
       "         0.0119495 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(acc_test-0.5,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significancia: 0.025\n",
      "Intervalo de confianza: 97.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf_1</th>\n",
       "      <td>649244.0</td>\n",
       "      <td>8.849670e-42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf_2</th>\n",
       "      <td>734852.0</td>\n",
       "      <td>1.999913e-23</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        statics       p-value     H0\n",
       "clf_1  649244.0  8.849670e-42  False\n",
       "clf_2  734852.0  1.999913e-23  False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = 0.5\n",
    "test = pd.DataFrame(columns=['statics','p-value','H0'])\n",
    "\n",
    "for clf in clf_names: \n",
    "    acc_test = accs_test_df.loc[clf]\n",
    "    w_test = wilcoxon(acc_test-mu)\n",
    "    if w_test.pvalue <= alpha_bonferroni:\n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,False]\n",
    "    else: \n",
    "        test.loc[clf]=[w_test.statistic,w_test.pvalue,True]\n",
    "\n",
    "print(f'Significancia: {alpha_bonferroni:.2}')\n",
    "print(f'Intervalo de confianza: {100*(1-alpha_bonferroni)}')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('fairness1.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc5a03d0949048036a82bc8df2a1f9a734ae5fa45f6ea724030c79b47976db34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
